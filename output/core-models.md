# The Two Main Taxonomies for Audio Cognition

*Source: Baldwin, C. L. (2012). Auditory Cognition and Human Performance. CRC Press.*

---

## 1. Baddeley's Working Memory Model

**Question it answers:** *How is information held and manipulated in the mind?*

### Structure

```
┌─────────────────────────────────────┐
│         CENTRAL EXECUTIVE           │
│    (attention control, switching,   │
│     coordination, inhibition)       │
└───────────────┬─────────────────────┘
                │
        ┌───────┴───────┐
        ▼               ▼
┌───────────────┐ ┌───────────────┐
│ PHONOLOGICAL  │ │  VISUOSPATIAL │
│     LOOP      │ │   SKETCHPAD   │
│               │ │               │
│ ┌───────────┐ │ │  (visual &    │
│ │  Store    │ │ │   spatial     │
│ │  (~2 sec) │ │ │   imagery)    │
│ └─────┬─────┘ │ │               │
│       ▲       │ │               │
│ ┌─────┴─────┐ │ │               │
│ │ Rehearsal │ │ │               │
│ └───────────┘ │ │               │
└───────────────┘ └───────────────┘
     VERBAL           SPATIAL
```

### Key Quote

> "Baddeley's three-component working memory system consists of a **central executive**, attentional controlling system and **two slave systems**. The slave systems consist of a **visuospatial sketch pad** for processing and manipulating visual images and a **phonological or articulatory loop** for manipulation of speech-based information."

### Components

| Component | Function | Capacity |
|-----------|----------|----------|
| **Central Executive** | Attention control, task switching, coordination, inhibition | Limited attentional resources |
| **Phonological Loop** | Holds and rehearses speech-based information | ~2 seconds of speech |
| **Visuospatial Sketchpad** | Processes and manipulates visual/spatial imagery | Limited visual-spatial items |

### Phonological Loop Sub-Components

| Sub-Component | Function |
|---------------|----------|
| **Phonological Store** | Passive buffer holding speech sounds for ~2 seconds |
| **Articulatory Control Process** | Active subvocal rehearsal; converts text → phonological code |

### What It Predicts

- **Verbal tasks** (speech, reading, numbers) compete for the **phonological loop**
- **Spatial tasks** (navigation, imagery) compete for the **visuospatial sketchpad**
- **Complex tasks** requiring coordination tax the **central executive**
- Capacity is limited (~2 seconds of speech in the phonological store)

### Example Tasks by Component

| Component | Example Tasks |
|-----------|---------------|
| **Central Executive** | Dual-task coordination, task switching, Stroop, random number generation |
| **Phonological Store** | Digit span, word span, non-word repetition |
| **Articulatory Rehearsal** | Articulatory suppression, word length effect tasks |
| **Visuospatial Sketchpad** | Corsi blocks, mental rotation, visual pattern span |

---

## 2. Wickens' Multiple Resource Theory (MRT)

**Question it answers:** *Why do some task combinations interfere more than others?*

### Structure

```
RESOURCE DIMENSIONS
│
├── INPUT MODALITY
│   ├── Visual
│   └── Auditory
│
├── OUTPUT MODALITY
│   ├── Manual (hands)
│   └── Vocal (speech)
│
├── PROCESSING CODE
│   ├── Verbal (language, text, speech)
│   └── Spatial (locations, movements)
│
└── PROCESSING STAGE
    ├── Perceptual (encoding input)
    ├── Central (thinking, deciding)
    └── Response (executing output)
```

### Key Quote

> "According to MRT, tasks can compete for common mechanisms with functionally separate 'reservoirs' or pools of attentional capacity in **three ways**: First, tasks may compete for the same **modality of input** (visual vs. auditory) or **response** (vocal vs. manual). Second, tasks can compete for the same **stage of processing** (perceptual, central, or response execution). Third, tasks may compete for the same **code** of perceptual or central processing (verbal vs. spatial)."

### The Four Dimensions

| Dimension | Options | Description |
|-----------|---------|-------------|
| **Input Modality** | Visual / Auditory | How information enters the system |
| **Output Modality** | Manual / Vocal | How responses are made |
| **Processing Code** | Verbal / Spatial | Format of mental representation |
| **Processing Stage** | Perceptual / Central / Response | Where in the pipeline |

### What It Predicts

| Same... | Result |
|---------|--------|
| Input modality | More interference |
| Output modality | More interference |
| Processing code | More interference |
| Processing stage | Bottleneck |

**Golden rule:** Tasks sharing resources interfere. Tasks using different resources can run in parallel.

### Practical Examples

| Task Combination | Interference | Why |
|------------------|--------------|-----|
| Driving + listening to speech | LOW | Visual-spatial + Auditory-verbal (different everything) |
| Driving + reading map | HIGH | Both visual-spatial |
| Driving + hands-free phone | MEDIUM-HIGH | Both require central processing; conversation preempts |
| Reading + listening to lecture | HIGH | Both verbal code (even though different modalities) |
| Tracking task + verbal task | LOW | Spatial + Verbal (different codes) |

### The Auditory Preemption Exception

> "Auditory ATC communications have been shown to be more disruptive in the visually demanding task of pilots... Cross-modality performance is thought to suffer in this paradigm because the **auditory task 'preempts'** the continuous visual task."

Auditory information has special power to grab attention and interrupt visual tasks, even when MRT would predict otherwise.

---

## Side-by-Side Comparison

| Aspect | Baddeley | Wickens |
|--------|----------|---------|
| **Focus** | Memory storage & manipulation | Task interference & time-sharing |
| **Origin** | Cognitive psychology | Human factors / ergonomics |
| **Core question** | "How do we hold info in mind?" | "Why do some task pairs conflict?" |
| **Main split** | Verbal vs Spatial | Modality × Code × Stage |
| **Bottleneck** | Central Executive | Central Processing Stage |
| **Practical use** | Understanding memory limits | Designing multi-task interfaces |

---

## How They Relate

> "Similar predictions for interference can be derived from Baddeley's model of working memory, in which the phonological loop and the visuospatial sketch pad are thought to process different types of information... **Parallels have been drawn between the concepts of working memory structure and MRT**."

```
BADDELEY                     WICKENS
─────────                    ───────
Phonological Loop    ←→      Verbal Code + Auditory Input
Visuospatial Sketchpad ←→    Spatial Code + Visual Input
Central Executive    ←→      Central Processing Stage
```

---

## When to Use Which

| Use Baddeley when... | Use Wickens when... |
|----------------------|---------------------|
| Designing memory tasks | Designing multi-task environments |
| Understanding rehearsal/storage | Predicting task interference |
| Assessing individual WM capacity | Choosing display modalities |
| Studying language processing | Allocating info across channels |

---

## Summary

- **Baddeley** = What's happening inside the head (architecture)
- **Wickens** = What happens when you load up that architecture (interference)

Both models converge on the key distinction between **verbal** and **spatial** processing as separate resource pools, and both recognize that **central/executive processes** represent a bottleneck where capacity is most limited.

---

## Additional Models (Context)

| Model | What It Explains | Key Insight |
|-------|------------------|-------------|
| **Filter Theories** (Broadbent, Treisman) | Where attention selection happens | Early vs Late selection |
| **Atkinson-Shiffrin Modal Model** | Memory stages | Sensory → STM → LTM |
| **Echoic Memory** | Brief auditory storage | Short-term (200-300ms) + Long-term (2-4s) stores |
| **Processing Codes Pipeline** | How audio is encoded | Acoustic → Phonological → Lexical → Semantic |

---

*Extracted from Chapters 4 & 5 of Baldwin (2012)*


# 10 Key Experiments in Auditory Cognition & Mental Workload

**Source:** *Auditory Cognition and Human Performance* (Baldwin, 2012)
**Extracted**: January 8, 2026

The following table summarizes ten pivotal experiments cited in the text that defined the models of Auditory Attention, Working Memory, and Mental Workload.

| **Experiment / Researcher** | **Associated Model** | **Methodology** | **Research Question** | **Key Finding / Proof** |
| :--- | :--- | :--- | :--- | :--- |
| **1. Cherry (1953)**<br>*Dichotic Listening* | **Broadbentâ€™s Early Filter Theory**<br>(Bottleneck Model) | Participants listen to two different messages presented simultaneously to left/right ears and "shadow" (repeat) one. | Can we attend to two messages at once? What happens to unattended info? | Participants could not recall *any* semantic content from the unattended ear, only physical traits (gender, pitch). **Proof:** Attention acts as an early "all-or-none" filter based on physical cues. |
| **2. Moray (1959)**<br>*Cocktail Party Effect* | **Challenges Early Filter**<br>Supports Late/Attenuation | Dichotic listening task, but the participant's **name** is inserted into the *unattended* message. | Does the filter block *all* meaning, or does high-value info break through? | 33% of participants heard their own name in the unattended ear. **Proof:** The filter is not absolute; "important" stimuli can penetrate the bottleneck (or are processed pre-attentively). |
| **3. Treisman (1960)**<br>*Message Switching* | **Attenuation Theory**<br>(Leaky Filter) | Dichotic listening where the meaningful sentence switches from the attended ear to the unattended ear mid-stream. | Do participants follow the *ear* (instruction) or the *meaning*? | Participants involuntarily switched ears to follow the sentence's meaning. **Proof:** Unattended info is not blocked but "attenuated" (turned down); meaning is analyzed before selection. |
| **4. Sperling (1960) / Moray et al. (1965)**<br>*Partial Report* | **Atkinson-Shiffrin**<br>(Sensory/Echoic Memory) | Listeners hear a rapid array of items. A cue (light/tone) *after* the stimulus indicates which subset to recall. | Is the bottleneck in *perception* (seeing/hearing) or *memory* (reporting)? | Recall was high for *any* cued row immediately after stimulus but decayed rapidly. **Proof:** A high-capacity "Sensory Register" (Echoic Memory) exists but lasts only 2-4 seconds. |
| **5. Miller & Licklider (1950)**<br>*Continuity Illusion* | **Auditory Scene Analysis**<br>(Top-Down Processing) | A steady tone is interrupted by silence (gap) vs. interrupted by a burst of loud noise. | Does the brain perceive a gap, or does it "fill in" the missing sound? | If noise masked the gap, listeners heard the tone as continuous. **Proof:** The brain uses "Schema" (Top-Down inference) to restore masked sounds (Phonemic Restoration). |
| **6. Bregman & Campbell (1971)**<br>*Stream Segregation* | **Auditory Scene Analysis**<br>(Primitive Grouping) | A sequence of High (H) and Low (L) tones is played rapidly (HLHLHL). | How does the auditory system organize rapid, alternating sounds? | At high speeds, perception splits into two separate streams (H-H-H and L-L-L). **Proof:** Frequency separation and speed trigger automatic "Stream Segregation" (grouping by similarity). |
| **7. Baddeley & Hitch (1974)**<br>*Dual-Task Interference* | **Working Memory**<br>(Multi-Component) | Participants perform a reasoning task while holding a sequence of digits (0-8) in memory. | Is Short-Term Memory a single unitary workspace? | Reasoning slowed but did not collapse, even with high digit load. **Proof:** WM has separate components (Phonological Loop vs. Central Executive); it is not just one "box." |
| **8. Daneman & Carpenter (1980)**<br>*Listening/Reading Span* | **Capacity Theory**<br>(Resource Model) | Listen to sets of sentences, verify logical truth (True/False), and recall the *last word* of each sentence. | Is WM capacity just passive storage, or storage + processing? | "Span" scores (storage + processing) predicted reading comprehension better than simple digit span. **Proof:** WM is a dynamic, limited resource shared between processing and storage. |
| **9. Wickens (1984)**<br>*Cross-Modal Time Sharing* | **Multiple Resource Theory**<br>(MRT) | Compared performance when doing Visual+Visual tasks vs. Visual+Auditory tasks. | Are attentional resources a single "fuel tank" or multiple specialized pools? | Visual+Auditory performance was superior to Visual+Visual. **Proof:** Resources are pooled by modality (Input), Code (Verbal/Spatial), and Stage. Cross-modal tasks reduce interference. |
| **10. Kramer et al. (1987)**<br>*Auditory Oddball (P300)* | **Mental Workload**<br>(Neuroergonomics) | Pilots flew a simulation (Primary) while ignoring occasional "oddball" tones (Secondary). Measured P300 brain waves. | Can we measure "mental effort" physiologically without asking the user? | As flight difficulty increased, the P300 amplitude to the tones *decreased*. **Proof:** Brain resources are limited; high primary load "steals" resources from processing the background tones. |

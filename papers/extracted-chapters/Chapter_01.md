# Unknown Chapter

*Source: Auditory Cognition and Human Performance by C. L. Baldwin (2012)*

---

# 1 **Hearing *****The Neglected Sense ***

## **INTRODUCTION **

Being able to hear and understand sounds—auditory processing—greatly enriches our lives and enables us to accomplish many tasks essential to survival. Although we engage in this process continuously throughout our lives, many may fail to appreciate that the seemingly automatic task of auditory processing often involves considerable mental effort to accomplish. Consider the following examples:

Lara is driving down the highway listening to a news program on the radio when she hears the name of her hometown. To better listen to and understand the subsequent story, she turns up the volume on the radio and quits eating popcorn from the sack on the seat next to her.

Johan is really hoping to get a chance to interview for a new position and feels he must show his knowledge of the topics discussed. The restaurant is crowded and noisy, and he struggles to hear so that he can follow the conversation. He concentrates, turns his visual attention to each speaker, and then realizes at the end of the lunch that he has barely touched his food.

In each of the scenarios, the effort required for auditory processing became more evident because it occurred in a situation when the person was engaged in other tasks (i.e., driving and trying to eat lunch). Simultaneous visual demands from the driving task were placed on Lara, and she chose to temporarily shed the task of eating as well as turn up the volume on the radio to allow her to focus more intently on the listening task. For Johan, visual speech cues aided his ability to understand the verbal cues. Auditory processing requires effort, even under the best of listening circumstances, although this effort may go unnoticed until the situation becomes more challenging. Challenges to auditory processing can stem from noisy or degraded listening situations, faint signals, or the concurrent demands of other tasks that must be performed simultaneously. Understanding these relationships is the focus of this book.

People use their auditory capabilities to communicate with each other, to locate sirens, oncoming traffic, and a host of other potentially dangerous objects in the environment. Auditory processing also enriches our lives in countless ways: Consider the pleasure of listening to one’s favorite music, the relaxing sounds of a babbling brook, or the heartwarming sound of a child’s debut in the grade school choir. Although most of us seem to accomplish such tasks with little conscious effort, our ability to process the auditory world around us is nothing less than remarkable.

**FIGURE 1.1 **Paul Broca.

The human brain, in conjunction with the ear, has evolved in such a way that it enables humans to organize and interpret the complex array of sounds heard in everyday life. Remarkably, we are able to simultaneously segregate multiple sources of sounds into their individual units while combining individual components of each sound stream into meaningful wholes. During the Baroque era (1600–1750), composers such as Johann Sebastian Bach made use of some of these remarkable principles of auditory processing that were evidenced, if not fully understood, to suggest to the listener something other than what was actually presented. For example, Bach used this auditory streaming illusion in his Partita no. 3 for solo violin in E major to suggest two melody lines. This technique came to be known as *virtual polyphony *(Bregman, 1990).

In the 19th century, localized brain structures that had evolved to carry out specific language-processing tasks were identified by the seminal work of physicians such as Paul Broca ( Figure 1.1 ) and Carl Wernicke (Kaitaro, 2001). This early work relating language functions to hemispheric specialization and modular organization of the brain was a significant contributing factor to the development of modern neuroscience (Banich, 2004; Corballis, 2000). However, despite the significance of early contributions in the area of auditory processing, and language processing in particular, the auditory sense has often been less appreciated than its cousin sense, vision.
## **THE BATTLE OF THE SENSES: VISION VERSUS AUDITION **

In his engaging essays, *The Five Senses *, Gonzalez-Crussi (1989) reminded us that Aristotle first noted that sight and hearing were what distinguished humans from the animals because it was these two senses, he argued, that allowed the unique human ability of aesthetic appreciation—of art and music—a quality that animals and robots lack. Although Aristotle’s argument can be debated, most people seem to agree with the supremacy of vision and of the secondary role of audition.

If you could only retain one of your five senses, which one would you choose? Over the last several years, I have posed this question to hundreds of students in my sensation and perception classes, asking them to choose the sense (among sight, hearing, taste, smell, or touch) that they consider most valuable and cherished. Generally, about two thirds of the class will choose sight. A majority of the remaining third will choose hearing, and a few students will choose from the remaining three.

Helen Keller, who had neither sight nor hearing, is reported to have differed from this majority sentiment. She said that of the two, she missed hearing the most. For though an inability to see separated her from experience with objects, the inability to hear separated her from experience with people (Ackerman, 1990). Auditory processing, and speech in particular, play a critical role in communication and social interaction for most humans across the entire life span. Still, most people (unless they are accomplished musicians) seem to value their ability to see more than their ability to hear. As if to underscore this common sentiment, the study of vision has received considerably more attention from the scientific community than has audition over the course of the last century.

Vision has been the object of prolonged and more extensive scientific research than has auditory processing. This is true both of the basic sciences of physics, biology, and psychology and in applied areas such as engineering and human factors (Bregman, 1990). Moreover, even within the field of audition, higher-order auditory processes (auditory scene analysis, auditory streaming, auditory recalibration, and language perception) have received considerably less study than lower-level processes such as loudness and pitch perception (Bregman, 1990; Plomp, 2002). The relative neglect of higher-level audition relative to vision is evidenced in the applied areas of human performance research as well as in the related disciplines of sensory, perceptual, and cognitive psychology. As a result, many key issues regarding how humans process auditory information remain poorly understood, whereas the basic low-level mechanisms of hearing are well known.

Despite its secondary status (to vision) in the scientific mainstream, many landmark contributions to the science of auditory processing were made in the 20th century. A notable example was work at Bell Laboratories, particularly when it was under the directorship of Harvey Fletcher (1927–1949). Fletcher published a widely read book, *Speech and Hearing *, in 1929. For a more recent edition, see Fletcher’s 1953 edition. By the late 1950s and early 1960s, a few prominent researchers had made major progress in areas that would lay the foundation for our current understanding of auditory cognition. Much of this early work involved the examination of differences between processing information in visual versus auditory modalities. A few researchers intentionally focused their attention on auditory processing. This focus is illustrated by the introductory comments of Robert Crowder at a conference entitled, The Relationships Between Speech and Learning to Read, held in the early 1970s. In the proceedings of the conference, Crowder (1972) stated:

Direct comparisons between the visual and auditory modes will be drawn where appropriate; however, since (as invariably seems to be the case) visual work is considerably farther advanced than auditory, most of my talk will be directed to the properties of auditory memory. (p. 252)

Other researchers who contributed significantly to our early understanding of auditory processing include Donald Broadbent, Colin Cherry, Anne Treisman, Reiner Plomp, Albert Bregman, and Neville Moray. Much of their work as it relates to information processing and mental workload, or auditory cognition, is examined throughout further chapters of this book. As a prelude to a discussion of auditory cognition, I turn first to a brief history of early work focusing on the role of sensory processing in applied human performance research.
## **EARLY HUMAN PERFORMANCE RESEARCH **

Research in the area of human performance capabilities and limitations in applied settings gave rise to the field now known as human factors, or ergonomics. During World War I, prior to the growth of human factors as a discipline, much of the applied work of psychology focused on the area of personnel selection and training, or what has sometimes been called “fitting the human to the task or machine” (Wickens, 1992). Human factors as a field gained major impetus during and after World War II as it became clear that the contributions of psychology to personnel selection and training were inadequate for the successful implementation and use of emerging technologies (Sanders & McCormick, 1993). Experimental psychologists who became the pioneers of early human factors research, such as Norman Mackworth and Paul Fitts, were called in to analyze the operator-machine interface (Wickens, 1992). Mackworth’s early work on factors affecting sustained attention or vigilance in radar monitors and the situations in which visual detection abilities become degraded (Mackworth, 1948, 1949) is illustrative of early human factors research. The proliferation of visual displays resulted in an emphasis on visual research in this early human factors effort.

In the postwar period, many psychologists turned from examining the immediate practical concerns of human performance in the operator-machine interface to more basic research issues. During the 1950s through the 1970s, the field of cognitive psychology witnessed a rebirth (Anderson, 2000). The new direction in cognitive psychology had at its core a focus on examining how humans process information, with particular emphasis on the role of attentional factors. The information-processing approach is now evidenced throughout the field of cognitive psychology, including the study of higher-level auditory processing (Anderson, 2000).
## **EARLY DEVELOPMENTS IN MODERN COGNITIVE PSYCHOLOGY **

Donald Broadbent played a key role in the reemergence of cognitive psychology. His work revived interest in cognition following several decades during the 1920s to 1950s when the behaviorist approach dominated American psychology. More importantly, Broadbent was the principal architect of the information-processing approach to psychology, which was later to become the dominant model in cognitive psychology during the second half of the 20th century. Broadbent’s (1958) seminal book, *Perception and Communication *, presented considerable research in the area of auditory selective attention as well as the first systematic model of information processing. Broadbent’s filter theory of attentional processing is discussed in a subsequent chapter.

During this era after World War II, auditory tasks, and the dichotic listening paradigm in particular, were used extensively to explore attentional processes (Cherry, 1953a; Moray, 1969; Moray, Bates, & Barnett, 1965; Treisman, 1960, 1964b). The dichotic listening paradigm (listening to two messages simultaneously—usually a different message in each ear) provided an important means of early exploration in the new era of cognitive psychology. A wealth of information exists in this early literature, much of which has direct relevance to our current understanding of auditory cognition and therefore is explored in subsequent chapters. However, outside the arena of investigations of attentional processing, visual processing still maintained a primary role in cognitive psychology.

George Sperling, another key figure in the early stages of the “cognitive revolution,” made major contributions to advancing knowledge and understanding of information processing. In particular, Sperling’s seminal work presented evidence for the existence of a temporary sensory store capable of holding information until it could be attended to and processed by relatively more long-lasting memory systems (Sperling, 1960, 1967). Sperling’s “partial report” paradigm was to become an extremely useful tool for many psychologists seeking to further examine the role of sensory characteristics in the initial stages of information processing.

While Sperling and numerous others of his day concentrated primarily on visual information processing, a few researchers, notably Neville Moray (Moray, 1969; Moray et al., 1965) as well as Crowder and colleagues (Darwin, Turvey, & Crowder, 1972), applied Sperling’s paradigm to examinations of auditory information processing. Their work is also discussed in further chapters. However, again with a few notable exceptions, investigations of visual processing took precedence over auditory processing in the field of cognitive psychology. There was a similar relative neglect of auditory processing in the field of sensation and perception.
## **SENSATION AND PERCEPTION RESEARCH **

Visual processing dominated the early days of sensory and perceptual research. Textbooks on sensation and perception prior to 1965 limited their coverage of auditory processing to basic psychophysical auditory qualities, such as loudness and pitch perception, the physiology of the auditory system, and at most perhaps coverage of the perceptual aspects of auditory localization (Bregman, 1990). Due to an emphasis on visual processing, our current understanding of the psychophysics and neural mechanisms involved in vision is far advanced relative to that of audition.

The neural mechanisms and structural mechanisms relevant to visual processing received considerable early attention. In the late 1950s and early 1960s, Hubel and Wiesel conducted pioneering work examining information coding and feature detection of individual cells in the lateral geniculate nucleus and the visual striate cortex of the cat brain (Hubel, 1960; Hubel & Wiesel, 1959, 1962; Moray, 1969). Analogous work on the auditory neural pathways was sparse and received little attention at the time, relative to the impact of Hubel and Wiesel’s Nobel Prize-winning work.

In fact, in many areas ranging from contextual effects stemming from the neural processes of lateral inhibition (Holt & Lotto, 2002) to the identification of parallel processing streams for visual object identification and object location (Courtney & Ungerleider, 1997; Ungerleider & Mishkin, 1982), our current understanding of visual phenomena greatly exceeds our knowledge of analogous auditory phenomena. However, this research gap is narrowing.

Recent empirical research indicated that the central auditory system consists of numerous neural mechanisms and modules that carry out specific auditory processing tasks that in many ways are analogous to the specialized mechanisms observed in the visual processing system. For instance, recent evidence indicated that, much like the parallel processing streams found in the visual system, the auditory system is characterized by separate processing streams—one stream involved in processing speech stimuli and another utilized in processing auditory spatial information (Belin & Zatorre, 2000; Rauschecker & Tian, 2000; Zatorre, Bouffard, Ahad, & Belin, 2002). Further, the auditory system appears to have a specific voice-selective region that responds primarily to vocal stimuli rather than nonvocal stimuli in ways similar to the face-selective areas of the visual cortex (Belin, Zatorre, Lafaille, & Ahad, 2000). Contemporary findings such as these are discussed in detail if they are relevant to an understanding of auditory cognition, particularly the mental workload requirements of auditory processing tasks.
## **SCOPE OF THIS BOOK **

Plomp (2002) pointed out that the aim of hearing research is to understand how sounds presented to the ear are translated by the hearing process into perception. The main premise of this book is that this process requires mental effort. This book presents for the first time a comprehensive examination of the mental effort involved in several different aspects of auditory processing. In addition to theory, numerous recent empirical investigations and everyday examples are presented to illustrate the interaction of sensory and cognitive processes. The effect of acoustic degradation on task performance and the impact of combining tasks that require auditory processing in addition to sensory processing in other modalities are emphasized.

Auditory processing involves extensive coordination between peripheral sensory detectors and central processing mechanisms located in both hemispheres of the brain. The more degraded the peripheral input, the harder the brain has to work, leaving fewer resources available for remembering what has been heard. For example, when listening to spoken material that is “hard to hear,” fewer cognitive resources will be left for interpreting the semantic and emotional content of the communication and remembering what was heard, relative to when the speech is clearly audible (Baldwin & Ash, 2010; Wingfield, Tun, & McCoy, 2005). At the level of the brain, the left and right hemispheres work together to segregate the acoustic information into meaningful units, using context to interpret both *what *is heard and *how *it is presented (Scott et al., 1997; Tervaniemi & Hugdahl, 2003). For spoken words, how the message is presented often underlies the practical and emotional significance of the communication. At the same time, the ventral (lower) and dorsal (upper) auditory pathways work together to process both what is being heard and where it is coming from (Romanski et al., 2000; Zatorre, Bouffard, et al., 2002b).

Disruptions at any stage or process in this complex interaction, which can become more common as we age, can result in devastating personal and economical costs. To give an everyday household example, wives may begin to feel that their middle-aged husbands just do not listen anymore; conversely, husbands may feel that their postmenopausal wives misinterpret the intention of nearly every conversation. On an economical level, communication failures and misinterpretation of sound information can result in considerable tragedy, as seen in numerous aviation accidents, medical room errors, and industrial catastrophes. For example, Ballas (1999) described how the misinterpretation of sounds in the cockpit contributed to the crash of Delta Flight 1141 in August, 1988. One of the pilots apparently mistook compressor stalls for engine failures, and this likely resulted in the engines not being immediately fully engaged, which might have prevented the crash. In another example, miscommunication between an air traffic controller and the captain and first officer of flight Dan Air B-727 at Tenerife in 1980 resulted in a crash that killed everyone on board, the worst aviation accident in history (Beaty, 1995).

The systems utilized in everyday life are becoming more technologically advanced, and the role of the human operator increasingly becomes that of a supervisory monitor of displays rather than an active manipulator of machinery (Parasuraman, 2003; Parasuraman, Sheridan, & Wickens, 2000). With these changes, consideration of the way people extract and process information increases in importance. Mental workload often increases in these technologically advanced environments even as physical workload decreases. Heavy reliance on sensory detection and information processing is required by the supervisory monitoring role. Performance limits today are more likely to be based on the functioning of sensory mechanisms to extract information and adequate mental resources to process the extracted information rather than on the physical capabilities that limited performance in the past.

In the technologically sophisticated environments present in today’s leisure and work environments, the potential for the demands on mental resources to exceed the human operator’s available attentional capacity are great. For example, since 2000 we have witnessed the introduction of a host of new devices in our automobiles. These range from cellular phones to sophisticated routing and navigational systems, collision warning systems, and “infotainment” centers. The introduction of these devices threatens to compromise safety as drivers struggle to divide their attention between the task of driving and the operation of other in-vehicle systems. We examine many of these new sources of sound in the next chapter and return to research aimed at improving the design of these systems in subsequent chapters, most notably in the chapter on auditory display design. Interface design based on good human factors principles has the potential to reduce mental resource demands, thus facilitating performance and reducing error. Consideration of the mental effort required for auditory processing is imperative for today’s operators, who face challenges associated with an increasingly complex array of informational displays.

Even if auditory devices are designed to facilitate safe operation, not all users will be able to use them effectively. Population aging, a global phenomenon, is resulting in an increasing proportion of these emerging devices being used by older adults. Age-related sensory and cognitive changes present in a large segment of today’s population call for reanalysis and possibly a redesign of many existing human-machine interfaces (Baldwin, 2002). The importance of issues related to aging warrants that they be discussed in a separate chapter. Chapter 10 is devoted to this discussion.

An understanding of the mental workload involved in auditory processing is relevant to a wide range of operational environments, including aviation, surface transportation, and medical facilities, as well as in classrooms of all types. The material presented in this book will benefit a wide range of audiences, including the classroom educator, students, and practitioners of audiology, cognitive science, and the applied psychological fields of human factors and industrial organizational psychology, as well as those who are affected either directly or indirectly by hearing loss or other auditory processing disorders. Several introductory chapters are included so that this wide readership can be accommodated. The latter portion of the second chapter is designed to promote a basic understanding of auditory processing at the perceptual level, and Chapter 3 is designed to introduce the novice reader to current theories of attentional processing and mental workload. Readers already well grounded in these areas may wish to skim or skip these sections and move on to the materials covered in subsequent chapters.

The primary goal of this book is to promote an understanding of the relationship between auditory cognition and human performance, particularly to highlight the nature of and situations in which the mental resource requirements of auditory processing may be compromised. A second goal of this book is to bring to the forefront the importance of increasing our understanding of auditory cognition and its relationship to human performance. Despite the relative neglect that auditory processing has received in earlier years, the auditory modality remains a potent source of information with several advantageous and unique characteristics.

This book is not intended to replace the many works on physiological aspects of hearing or acoustics. For further readings in that area, see the work of Moore (1995) and Yost (2006). Rather, this book is intended to extend the existing literature by focusing specifically on the mental workload or attentional processing requirements of auditory processing and its application in complex real-world tasks. Extensive consideration is given to such everyday tasks as language processing, extracting information from auditory displays, and the impact of auditory processing in conjunction with performing tasks in other modalities (i.e., visual, tactile, and olfactory).
### **Characteristics of Auditory Processing **

Humans are biologically adapted to process complex auditory information, most notably speech. One need only point to the fact that speech is a universal characteristic of all community-dwelling human beings to begin to understand the importance of speech processing. While across time and civilizations humans have always developed a spoken language, reading and writing have been relatively rare (Liberman, 1995). The universal characteristic of auditory processing in the form of speech was pointed out by Liberman in the following six primary observations.

First, all communities of humans have developed a spoken language, while many languages do not have a written form. When a written form does exist, it is typically used much less frequently than the spoken form.

Second, speech developed much earlier than writing in the history of the human species. The development of speech was perhaps the single most salient development in distinguishing humans from other species.

Third, speech occurs earlier in the development of the individual. Humans begin to comprehend and produce speech in infancy. It is several years later, if at all, before they are capable of utilizing written language forms (Liberman, 1995).

In addition, speech must be learned but need not be taught. Individuals of normal intelligence and functional capacity will learn to understand and produce speech with mere exposure. It is in this sense therefore that Liberman (1995) referred to speech as a precognitive process, much like learning to localize sound. Reading and writing, on the other hand, must be taught and therefore represent an intellectual achievement rather than a precognitive process.

Specific brain mechanisms have evolved to process spoken language. Reading and writing presumably utilize these mechanisms to some extent. However, the processing of written language must also rely on brain mechanisms that have not evolved for that specific purpose.

Last, spoken language is extremely flexible, adaptable, and capable of conveying a nearly infinite number of expressions. Written language has no independent existence without its spoken language base and therefore can only have utility to the extent that it transcribes its spoken counterpart (Liberman, 1995). The natural ease with which humans learn and process speech makes it an important component to be utilized in the design of human-machine interfaces. Also, the auditory modality has several unique and important characteristics as an information-processing channel.
### **The Auditory Channel **

The auditory channel has at least two characteristics distinct from the visual channel that have important implications for our understanding of human information processing and mental workload (Wickens, 1992). First, auditory information can be perceived from any direction and therefore is said to be omnidirectional. This characteristic of the auditory channel means that the listener does not need to focus on a specific spatial location or even be oriented in any particular direction to perceive a sound. Provided the auditory signal is salient enough to be heard, the listener is free to move or direct visual attention to other tasks without signal loss. On the contrary, visual signals require that an observer be in the direct line of sight of a display and further that the observers’ attention be directed to the visual display. As discussed in a subsequent chapter, the omnidirectional aspect of auditory processing allows drivers to keep their eyes on the road while receiving navigational instructions and allows pilots to maintain visual attention to flight displays while communicating with air traffic control.

The second distinct characteristic is that auditory information is typically transient. This characteristic of a limited temporal duration translates to the imperative that the operator must have sufficient mental resources and time to process an auditory signal in real time. Unlike visual signals, which typically remain in view and can often be reexamined, the listener is not free to repeatedly refer back to check the status or clarify the information presented in the auditory signal. Fortunately, the human auditory processing system has evolved in such a way that the auditory sensory store (referred to as *echoic memory *) is of much longer duration, relative to the visual sensory store (or *iconic memory) *. The benefits of a more persistent echoic sensory trace and the factors that affect its duration are discussed in more detail in further chapters because of their important implications for auditory processing in real-world settings.

The unique characteristics of auditory processing and the auditory channel have important implications for human performance. As previously stated, it is the premise of this book that all auditory processing requires mental effort. We turn now to the topic of mental effort and its quantification in terms of mental workload.
### **Mental Workload **

Mental workload is a multidimensional construct that in essence describes the level of attentional engagement and mental effort that a person must expend to perform a given task (Wickens, 1984). Measurement of mental workload essentially represents the quantification of this level of engagement in mental activity resulting from performance of a task or set of tasks. Specific techniques for accomplishing this quantification procedure are discussed in a subsequent chapter. However, regardless of the technique utilized, some common assumptions are as follows: Mental workload theory entails the assumption that (a) people have limited mental and attentional capacity with which to perform tasks; (b) different tasks will require different amounts (and perhaps different types) of processing resources from the same individual; and (c) two individuals might be able to perform a given task equally well, but one person may require more attentional resources than the other (Baldwin, 2003). Quantifying the mental workload of a given task or task set is critical to understanding, designing, implementing, and improving the systems humans use in their everyday lives. A key element of this design process (characterized by ergonomic/human factors design principles) is to develop systems that make efficient use of human mental processing capabilities to allow people to perform several simultaneous tasks without exceeding their mental processing capacity (Baldwin, 2003; Gopher & Donchin, 1986; Ogden, Levine, & Eisner, 1979).

The study of mental workload has played an important role in human factors research since the 1970s (Casali & Wierwille, 1983b; Gopher & Donchin, 1986; Hancock & Desmond, 2001; Kramer, Sirevaag, & Braune, 1987; O’Donnell & Eggemeier, 1986; Wierwille & Connor, 1983; Wierwille, Rahimi, & Casali, 1985). In fact, mental workload took a “central theme in laboratory-based empirical work,” as pointed out by Flach and Kuperman (2001, p. 433), during the 1970s and 1980s. Auditory tasks have frequently been used as secondary task indices of mental workload (Backs, 1997; Fowler, 1994; Harms, 1986, 1991; Kramer et al., 1987). This area of research is explored in Chapter 6 , which focuses on the use of auditory tasks in cognitive research and in research aimed at assessing mental workload. Emphasis is placed on the intersection of peripheral auditory and central information-processing mechanisms and the critical role that this interaction has in influencing the mental workload requirements of auditory processing. The implications of this sensory- cognitive interaction for human performance are a unique contribution of this book.
## **CONCLUDING REMARKS **

Relative to visual processing, auditory processing has received little attention in the early research on human performance, including human factors research, much of early cognitive psychology, and early sensation and perception research. Some major exceptions to this relative neglect include investigations of attentional processing and the study of language, which has been a focus of considerable research for decades (Bagley, 1900–1901; Broadbent, 1958; James, 1890/1918). Over a century ago, Bagley (1900–1901) realized that speech understanding involves the interaction of sensory and cognitive processes. Bagley observed the essential role that context played in speech processing. This book expands on that early realization, looking at the many factors that affect the mental workload associated with auditory processing. It also may lay the groundwork for new growth in a burgeoning area of human performance research: applied auditory cognition.
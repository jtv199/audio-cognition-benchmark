Source: Bregman_1990_ASA_Ch4_SchemaBasedSegregation.pdf
First 2000 words extracted
================================================================================

Chapter 4 Schema-Based Segregation and Integration In chapters 2 and 3, we have studied the two types of primitive grouping, sequential and spectral, that help to solve the problem of auditory scene analysis. We have treated them as if they were fully explainable as automatic innate processes that act without conscious control. However, this cannot be the whole story about the organiza- tion of auditory signals. In many cases, hearing a signal in a mixture of sounds depends on conscious effort and prior learning. In the present chapter, I would like to consider the contribution made by attention and knowledge in the perceptual analysis of sig- nais. I will not be able to provide much of an account of the internai machinery of knowledge-based analysis. Little relevant research has been done. My main emphasis will be on trying to strip away the contribution of knowledge and attention in auditory scene analysis so that the workings of the primitive process can be seen more clearly. The nineteenth-century physicist Hermann Helmholtz distin- guished between analytic and synthetic listening to complex tones. Using anaiytic listening, he could hear out a partial of the tone. With a more natural, synthetic attitude he would hear the holistic prop- erties of the tone. He argued that when listening for the partials of a complex tone, "the attention of the observer has generally to be drawn to the phenomenon he has to observe...until he knows pre- cisely what to look for."509 I do not agree that segregation is the product of attention while integration is the result of inattention. However, it does seem true that attention and learning can play a role when we extract some of the components of mixtures for the pur- poses of pattern analysis. The goal of this chapter will be to determine whether there is any basis for distinguishing between two classes of processes in auditory scene analysisone automatic and unlearned and the other involving learning and attention. I have argued earlier that recognizing the timbre of a signal when it is mixed with other ones depends on scene analysis. The auditory This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444583/9780262269209_cad.pdf by UNIV OF MELBOURNE user on 08 December 2025 

396Chapter 4 system must group all the components of that signal into the same perceptual stream. We saw that this was made possible by acoustic factors that bound the group of components together and at the same time distinguished them from the other ones that were present. However, J. O. Nordmark has described a number of situations in which the timbres of signals embedded in mixtures can be recognized despite the fact that there is no simple acoustic basis for segregating the partials of that signal from the mixture. 510 He has mentioned, as examples, mixtures of amplitude-modulated tones, square waves and filtered pulse trains, in which the pitch and intensity are held constant and there are no spectral or common fate cues to distinguish their partials from one another. The timbre of individual signals in the mixture is discernible. While Nordmark did not supply enough detail in his report to allow us to determine whether there was any acoustic basis for hearing out the component timbres, his examples are not the only ones that lead us to the suspicion that factors other than the ones surveyed so far are at play. Other examples occur with speech sounds. Mixtures of two syn- thetic vowels can be created in which there are no spectral features that we know of that can group the harmonics or the formants into those that define the individual vowels. J have created the pair "ee" and "ah" in the laboratory. Both had the same onset and offset times, the same pitch at each moment of time, and the same loudness contour. Yet I was able to clearly hear the two individual vowels. More formal experiments using this sort of stimulus have been done by Michael Scheffers, with similar results.511 Scheffers fed either glottal pulses or white noise into a series of filters to create spoken or whispered vowels, respectively. In both cases, his listeners performed remark- ably well in recognizing them. In the recognition test, since they had to choose the two vowels that were present in the mixture from a set of eight possibilities, the likelihood of guessing by chance was only 3.6 percent. Yet both vowels were correctly identified 45 percent of the time when the two were spoken and 26 percent of the time when they were both whispered. There have been other cases where the auditory system has suc- ceeded in putting spectral regions together for purposes of speech recognition despite the fact that there were acoustic cues telling it to segregate them. For example, James Cutting has synthesized syllables such as "da" by means of two formants and sent the different for- mants to different ears of the listener.512 When the two formants had different fundamental frequencies, the listener heard two sounds. This occurred, presumably, because both the different spatial loca- This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444583/9780262269209_cad.pdf by UNIV OF MELBOURNE user on 08 December 2025 

Schema-Based Segregation and Integration397 tions and the different fundamental frequencies indicated the existence of two separate sounds. Just the same, they heard the correct syllable (from among "ba", "da", and "ga"), an accomplishment that re- quired them to integrate information from their two ears. Their rec- ognition succeeded despite, rather than with the aid of, acoustic cues for grouping. A host of other researchers have found essentially the same effectphonetic integration in the face of acoustic cues that favor the segregation of acoustic components.513 There is another case of auditory organization for which primitive segregation is not a sufficient explanation. The perceptual restoration of missing material in the continuity illusion does not lend itself to being explained by a scene analysis based on acoustic cues. For exam- ple, in phonemic restorations the restored sounds tend to be words that fit meaningfully into the sentence. Clearly the selection of the appropriate components from the noise burst must be based on some- thing other than the immediately present sound because the restored material is not identical to what came either before or after the noise. It must depend not just on the sounds that are present, but the listen- ers' knowledge of their language. Nature of Primitive and Schema-Based Organization These examples all point to the fact that scene analysis can use a more sophisticated knowledge of the signal than what I have described earlier. I am therefore going to propose that there are two different processes in the construction of auditory representations, one that I will call primitive scene analysis and the other schema-driven con- struction of descriptions. The use of the word primitive is meant to suggest that the process is simpler, probably innate, and driven by the incoming acoustic data. The schema-driven (hypothesis-driven) process is presumed to involve the activation of stored knowledge of familiar patterns or schemas in the acoustic environment and of a search for confirming stimulation in the auditory input. This dis- tinction is very much like the common distinction in information- processing theory between bottom-up and top-down processing. Both processes are concerned with the decomposition of mixtures of information so that the right combination of information can enter into the description of an environmental sound. However, the primi- tive mechanism does this without reference to the recognition of spe- cific familiar sounds, whereas the sophisticated ones select the right components as a part of the process of matching stored schemas for familiar environmental sounds to the incoming data. This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444583/9780262269209_cad.pdf by UNIV OF MELBOURNE user on 08 December 2025 

398Chapter 4 Properties That May Distinguish the Two Systems The approach that I plan to take is to assume that the primitive seg- regation process employs neither voluntary attention nor past learn- ing. Therefore I will call the process schema-driven if it uses either of these capacities. In my definition of the schema-driven process, I may be accused of conflating two different processes. It is possible that the use of voluntary attention and the use of prior learning are not the same thing at all. However, I have two reasons for grouping them. First is, I am trying to strip away everything that is not part of the primitive process, to see whether some "pure" properties of the primitive process can be isolated. I feel that it is necessary to do so because there exist, in the research on perceptual segregation, some contradictions that can be resolved only by assuming that there is more than one process at work. Second, another way of describing voluntary attention is to call it programmed attention, or attention that is under the control of an inner process that is trying to find some particular pattern in our sensory input. Since I look at schemas as control systems that deal with patterns in the environment, it is natu- ral to think of them as the ones that govern voluntary attention. We know that both attention and prior learning can affect the process of extracting signals from mixtures. Let us consider these in turn and see how they function. The concept of attention encompasses two distinct facts about the human mind. The first is that there are processes that can select part of the currently available sensory information for more detailed pro- cessing. Let me give an example: When you are asked to pay attention to sensations arising from your left foot, you will suddenly become aware of a set of experiences that were previously not part of your consciousness. This selective role of attention has been studied in au- dition mainly in a situation where a listener is trying to pay attention to one spoken message in the presence of a second one. 514 Many fac- tors have been shown to affect the ability to do this. Among these are the acoustic differences between the two messages. For example, if the messages are spoken on very different pitches, as happens when one is spoken by a man and the other by a woman, it is easier for the listener to attend to one of these and not be interfered with by the other. Other differences, such as in location, can assist this segrega- tion. The key factor that makes us think of this process as attention is that the listener is trying to hear one of the two messages. This notion of trying is central to the definition of attention. Why, then, did I argue earlier that these experiments tell us about primitive perceptual grouping? Why are they not really experiments on attention? After all, the listener is usually trying to accomplish the This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444583/9780262269209_cad.pdf by UNIV OF MELBOURNE user on 08 December 2025 

Schema-Based Segregation and Integration399 task of hearing a subset of sounds as a separable pattern in a mixture. This is a difficult question. When we use a person as a subject in an experiment, the successful completion of the task involves a large constellation of capacities, including the ability to hear the signal, to understand the instructions, to sit still, to attend to the signals, to make some sort of judgment, to turn the judgment into words or numbers, and so on. If this is so, how do we know which process has been affected when the experimenter has manipulated some variable in an experiment? The answer is that we do not ever really know for sure, but we can make reasonable guesses based on common sense and on our prior understanding of these processes. For example, if it is easier to distinguish two voices when they are at different pitches, it is hard to see how the difference in pitches might affect the ability of the listener to sit still in the chair; we 
Source: Rauschecker_2009_MapsAndStreams.pdf
First 2000 words extracted
================================================================================

Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing Josef P Rauschecker1,2 & Sophie K Scott3 Speech and language are considered uniquely human abilities: animals have communication systems, but they do not match human linguistic skills in terms of recursive structure and combinatorial power. Yet, in evolution, spoken language must have emerged from neural mechanisms at least partially available in animals. In this paper, we will demonstrate how our understanding of speech perception, one important facet of language, has proﬁted from ﬁndings and theory in nonhuman primate studies. Chief among these are physiological and anatomical studies showing that primate auditory cortex, across species, shows patterns of hierarchical structure, topographic mapping and streams of functional processing. We will identify roles for different cortical areas in the perceptual processing of speech and review functional imaging work in humans that bears on our understanding of how the brain decodes and monitors speech. A new model connects structures in the temporal, frontal and parietal lobes linking speech perception and production. Our understanding of speech processing has both beneﬁted and suffered from developments in neuroscience. The basic brain areas important for speech perception and production were established in the nineteenth century, and although our conception of their exact anatomy and function has changed substantially, some of the ﬁndings of Broca 1 and Wernicke2 still stand (Supplementary Discussion 1 and Supplementary Fig. 1online). What has lagged behind is a good model of how the brain decodes spoken language and how speech perception and speech production are linked. For example, the frameworks for cortical processes and pathways have taken longer to form in audition than in vision, and animal models of language have severe limitations 3. The evolution of speech and language are likely to have depended on neural systems available in other primate brains. In this paper, we will demonstrate how our understanding of speech perception, one important facet of language, has proﬁted from work in nonhuman primate studies. Streams and hierarchies in nonhuman primate auditory cortex ‘What’ and ‘where’ pathways in vision and audition.A decade ago, it was suggested that auditory cortical processing pathways are organized dually, similar to those in the visual cortex ( Fig. 1 ) 4,5:t h a to n e main pathway projects from each of the primary sensory areas into posterior parietal cortex, another pathway into anterior temporal cortex. As in the visual system 6, the posterior parietal pathway was hypothesized to subserve spatial processing in audition while the temporal pathway subserved the identiﬁcation of complex patterns or objects. Per the directions of their projections in the auditory system, these pathways were referred to as the postero-dorsal and antero- ventral streams, respectively. Anatomical tract tracing studies in monkeys support separate ante- rior and posterior projection streams in auditory cortex 7,8. The long- range connections from the surrounding belt areas project from anterior belt directly to ventrolateral prefrontal cortex (PFC) and from the caudal (posterior) belt to dorsolateral PFC 9.T h i sl a t t e r ﬁnding provided evidence, on both anatomical and functional grounds10,11, for ventral and dorsal processing streams within auditory cortex. Single-unit studies in the lateral belt areas of macaques provided more direct functional evidence for this dual processing scheme. Tian et al. 12 found that when species-speciﬁc communication sounds are presented in varying spatial locations, neurons in the antero-lateral belt (area AL) are more speciﬁc for the type of monkey call. By contrast, neurons in the caudo-lateral belt (area CL) are more responsive to spatial location than neurons in core or anterior belt. This result indicates that ‘what’ processing dissociates from ‘where’ processing in rhesus monkey auditory cortex. The dual-stream hypothesis has found support from other studies 13,14. Recanzone and co-workers 15 found a tighter correlation of neuronal activity and sound localization in caudal belt, supporting a posterior ‘where’ stream. Lewis and Van Essen 16 described a direct auditory projection from the posterior superior temporal (pST) region to the ventral inferior parietal (VIP) area in the posterior parietal cortex of the monkey. Single-unit as well as imaging studies in monkeys also reveal functional specialization 17–21. Functional magnetic resonance imaging in nonhuman primates identiﬁed, ﬁrst, tonotopic maps on the superior temporal plane and gyrus 22 and, then, a ‘voice region’ in the anterior part of the superior temporal gyrus23, a voice region that projects further to the anterior superior temporal sulcus and ventrolateral PFC 24. Reversible cortical inactivation (using cortical cooling) in cat auditory cortex25 found that REVIEW HEARING Published online 26 May 2009; doi:10.1038/nn.2331 1Laboratory of Integrative Neuroscience and Cognition, Georgetown University Medical Center, Washington, DC, USA.2Centre of Excellence in Computational Complex Systems Research, Department of Biomedical Engineering and Computational Science, Helsinki University of Technology, Espoo, Finland. 3Institute of Cognitive Neuroscience, University College London, London, UK. Correspondence should be addressed to J.P.R. (rauschej@georgetown.edu) or S.K.S. (sophie.scott@ucl.ac.uk).718 VOLUME 12 [ NUMBER 6 [ JUNE 2009 NATURE NEUROSCIENCE © 2009 Nature America, Inc. All rights reserved. 

inactivating anterior areas leads to a deterioration of auditory pattern discrimination, whereas inactivating posterior areas impairs spatial discrimination. These studies corroborate the notion that an antero- ventral processing stream forms the substrate for the recognition of auditory objects, including communication sounds, whereas a postero- dorsal stream includes spatial perception as at least one of its functions. Hierarchical organization in the cerebral cortex combines elements of serial as well as parallel processing: ‘lower’ cortical areas with simpler receptive-ﬁeld organization, such as sensory core areas, project to ‘higher’ areas with increasingly complex response properties, such as belt, parabelt and PFC regions. These complex properties are generated by convergence and summation (Box 1 and Fig. 2). Parallel processing principles in hierarchical organization are evident in that specialized cortical areas (‘maps’) with related functions (corresponding to sub- modalities or modules) are bundled into parallel processing ‘streams’ . Furthermore, highly interconnected neural networks, dynamically modulated by different task demands, may also exist within hierarch- ical processing structures, and well known feedback connections are sometimes not sufﬁciently accounted for in hierarchical models. ‘What’ and ‘how’ pathways and the perception–action cycle. In addition to the ‘what/where’ model in vision 6, Goodale and Milner26 proposed that two pathways subserve behaviors related to perception and action. The auditory ventral pathway role in perception is largely consistent with a ‘what’ pathway, whereas the dorsal pathway takes on a sensorimotor role involved in action (‘how’), including spatial analysis. Fuster 27 advocates a similar distinction with regard to PFC and unites the two pathways into a perception–action cycle. We argue here that the ‘what/where’ and ‘perception/action’ theories differ mainly in emphasis. Dual processing streams in the auditory cortex of humans The concepts of auditory streams of processing can be a powerful framework for understanding functional imaging studies of speech perception 28,29 and for understanding aphasic stroke3. Human studies also conﬁrm the role of the postero-dorsal stream in the perception of auditory space and motion (see refs. 30 and 14 for review). But do more than two processing streams exist 31 (Fig. 3 )? The posterior superior temporal gyrus and inferior parietal cortex have long been implicated in the processing of speech and language, and ignoring these reports (Supplementary Discussion 1 ) and assigning an exclusively spatial function to the postero-dorsal auditory stream would be unwise. It is therefore essential to discuss how the planum temporale, the temporo- parietal junction and the inferior parietal cortex are involved in speech and language, and whether we can assign a common computational function to the postero-dorsal stream that encompasses both spatial and language functions. Antero-ventral stream for auditory object and speech perception Hierarchical organization. A meta-analysis of imaging studies of speech processing 32 reports an antero-lateral gradient along which the complexity of preferred stimuli increases, from tones and noise bursts to words and sentences. As in nonhuman primates, frequency responses show tonotopy, while core regions responding to tones are surrounded by belt areas preferring band-pass noise bursts 33.U s i n g high-ﬁeld scanners, multiple tonotopic ﬁelds34 and multiple processing levels (core, belt and parabelt) 35 can be identiﬁed in human auditory cortex. Auditory object identiﬁcation. This sort of hierarchical organization in the antero-ventral auditory pathway of humans is important in auditory pattern recognition and object identiﬁcation. As in animal models, preferred features of lower-order neurons combine to create selectivity for increasingly complex sounds36,37, and regions can be seen that are specialized in different auditory object classes (A.M. Leaver and J.P .R., unpublished data)38,39. Developments in how we conceive the structure of auditory objects 40,41 will help extend these kinds of investigations. Like their visual counterparts, auditory objects coexist based on many attributes, such as timbre, pitch and loudness, that give each its distinctive perceptual identity 41. Speech and voice perception. Within speech perception, there is evidence that speech sounds are hierarchically encoded, as the anterior superior temporal cortex responds as a function of speech intelligibility, and not stimulus complexity alone 42–44. Similarly, Liebenthal et al.45 and Obleser et al.46 showed that the left middle and anterior superior temporal sulcus is more responsive to consonant–vowel syllables than auditory baselines. Thus, regions within the ‘what’ stream show the ﬁrst clear responses to abstract, linguistic information in speech. Within these speech-speciﬁc regions of anterior superior temporal cortex, there may be subregions selective for particular speech-sound classes, such as vowels 38,46, raising the possibility that phonetic maps have some anatomical implementation in anterior temporal lobe areas. Activity related to speaker recognition also exists in antero-lateral temporal lobe areas39, sometimes extending into midtemporal regions as well. These human voice regions may be homologous, according to crude topological criteria, to monkey areas 23 mentioned above. This human ‘voice area’ in the anterior auditory ﬁelds seems to process detailed spectral properties of talkers47. Notably, speech perception and voice discrimination dissociate clinically, suggesting that the two are supported by different systems within the anterior and middle tem- poral lobes. Invariance and categorization. An important problem in the task of speech perception is that of invariance against distortions in the scale of frequency (for example, pitch changes; Fig. 4a)o rt i m e( f o re x a m p l e , compressions). For example, noise-vocoded speech, which simulates aspects of speech after cochlear implantation, is quite coarse in its spectro-temporal representation 48 (Fig. 4b ); it is, however, readily intelligible after a brief training session. Perceptual invariance is also Parietal lobe: ‘where’ Temporal lobe: ‘what’ PPC A1 V1 DLPFC VLPFC ST IT Figure 1 Dual processing scheme for ‘what’ and ‘where’, proposed for nonhuman primates on anatomical and physiological grounds. V1, primary visual cortex; A1, primary auditory cortex; IT, inferior temporal region; ST, superior temporal region; PPC, posterior parietal cortex; VLPFC, ventrolateral prefrontal cortex; DLPFC, dorsolateral prefrontal cortex. (Simpliﬁed from refs. 4,5 and combined with an existing scheme from the visual system from ref. 6.) NATURE NEUROSCIENCE VOLUME 12 [ NUMBER 6 [ JUNE 2009 719 REVIEW © 2009 Nature America, Inc. All rights reserved. 

important in the perception of normal speech, as the ‘same’ phoneme can be acoustically very different (owing to coarticulation) and still be identiﬁed as the same sound 49: the sound /s/ is different at the start of ‘‘sue’’ than at the start of ‘‘see, ’’ but remains an /s/. These examples of perceptual constancy are computationally difﬁ- cult to solve. This ability to deal with invariance problems is not unique to speech or audition; it is a hallmark of all higher cortical perceptual systems. The structural and functional organization of the anterior- ventral streams in both the visual and auditory systems could illustrate how the cerebral cortex solves this problem. For example, it has been suggested that visual categories are formed in the lateral PFC 50, which receives input from higher-order object representations in the anterior temporal lobe 10. In audition, using species-speciﬁc communication sounds, Romanski et al.51 found clusters of neurons in the macaque ventrolateral PFC encoding similar complex calls, and category-speciﬁc cells encoding single semantic categories have also been reported 52.I n humans, rapid adaptation studies with functional MRI in the visual 
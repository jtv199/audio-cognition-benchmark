Source: MMAU-Pro_2508.13992v1.pdf
First 2000 words extracted
================================================================================

MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence Sonal Kumar1*, ˇSimon Sedl´aˇcek2*, Vaibhavi Lokegaonkar1*, Fernando L´opez3,4*, Wenyi Yu5, Nishit Anand1, Hyeonggon Ryu6, Lichang Chen1, Maxim Pliˇcka2, Miroslav Hlav´aˇcek7, William Fineas Ellingwood8, Sathvik Udupa2, Siyuan Hou5, Allison Ferner9, Sara Barahona3, Cecilia Bola˜nos10, Satish Rahi11, Laura Herrera-Alarc´on3, Satvik Dixit 13, Siddhi Patil1, Soham Deshmukh 12, Lasha Koroshinadze 1, Yao Liu14, Leibny Paola Garcia Perera15, Eleni Zanou16, Themos Stafylakis16, Joon Son Chung6, David Harwath17, Chao Zhang5,18, Dinesh Manocha1, Alicia Lozano-Diez3, Santosh Kesiraju2#, Sreyan Ghosh1#, Ramani Duraiswami1# 1University of Maryland, College Park, USA, 2 Brno University of Technology, Czech Republic,3 Universidad Aut´onoma de Madrid, 4 Telef´onica, 5 Tsinghua University, 6 KAIST, Daejeon, 7 Phonexia, 8 Middlebury College, USA, 9 Tufts University, 10 Universidad de Buenos Aires, 11 Indian Institute of Technology, Bombay,12 Microsoft, 13 Carnegie Mellon University, USA, 14 Universiti Sains Malaysia, 15 Johns Hopkins University, USA, 16 Athens University of Economics and Business, 17 University of Texas, Austin, USA,18 Shanghai Artificial Intelligence Laboratory Corresponding authors:{sonalkum, sreyang}@umd.edu, * Core Contributors, # Core Advisors Abstract Audio comprehension-including speech, non-speech sounds, and music-is essential for achieving human-level intelligence. Consequently, AI agents must demonstrate holistic audio un- derstanding to qualify as generally intelligent. However, eval- uating auditory intelligence comprehensively remains chal- lenging. To address this gap, we introduce MMAU-Pro, the most comprehensive and rigorously curated benchmark for assessing audio intelligence in AI systems. MMAU-Pro con- tains 5,305 instances, where each instance has one or more audios paired with human expert-generated question-answer pairs, spanning speech, sound, music, and their combinations. Unlike existing benchmarks, MMAU-Pro evaluates auditory intelligence across 49 unique skills and multiple complex dimensions, including long-form audio comprehension, spa- tial audio reasoning, multi-audio understanding, among oth- ers. All questions are meticulously designed to require de- liberate multi-hop reasoning, including both multiple-choice and open-ended response formats. Importantly, audio data is sourced directly “from the wild” rather than from existing datasets with known distributions. We evaluate 22 leading open-source and proprietary multimodal AI models, reveal- ing significant limitations: even state-of-the-art models such as Gemini 2.5 Flash and Audio Flamingo 3 achieve only 59.2% and 51.7% accuracy, respectively, approaching ran- dom performance in multiple categories. Our extensive anal- ysis highlights specific shortcomings and provides novel in- sights, offering actionable perspectives for the community to enhance future AI systems’ progression toward audio gen- eral intelligence. The benchmark and code is available at https://sonalkum.github.io/mmau-pro. Introduction Comprehensive audio understanding-from spoken language to environmental sounds and music-is fundamental to hu- Pre-print. Under Review. man general intelligence. Correspondingly, AI systems must possess comparable capabilities for effective real-world in- teraction (Sakshi et al. 2025). Recent advancements in mul- timodal large language models (MLLMs) have led to the emergence of Large Audio-Language Models (LALMs), demonstrating notable audio comprehension skills (Ghosh et al. 2024, 2025b; Goel et al. 2025; Gong et al. 2024; Desh- mukh et al. 2023; KimiTeam et al. 2025; Xie et al. 2025a; Xu et al. 2025; Chu et al. 2024). Despite numerous bench- marks assessing progress toward Artificial General Intelli- gence (AGI) through text, audio intelligence evaluation re- mains notably underserved. Given audio’s inherent diversity and complexity, we contend that progress toward AGI is in- complete without strong audio intelligence capabilities-and that their rigorous evaluation remains an open challenge. Recently, several benchmarks have emerged to evaluate LALMs. MMAU (Sakshi et al. 2025), a pioneering com- prehensive benchmark, comprises 10,000 carefully selected audio clips across speech, sounds, and music, with single- turn, single-audio questions requiring knowledge and rea- soning. Following MMAU, MMAR (Ma et al. 2025) in- troduced more challenging queries, while MMSU (Wang et al. 2025b) expanded spoken language understanding assessments. Domain-specific benchmarks like Speech- IFEval (Lu, Kuan, and Lee 2025) focus on instruction- following and CMM (Leng et al. 2024) focuses on hallucina- tions. Nevertheless, existing benchmarks inadequately rep- resent the complexity of realistic auditory scenarios - such as multiple and overlapping audios, long-duration inputs, open-ended answers, and culturally varied content-which demand deeper comprehension and multi-hop reasoning be- yond basic recognition. Our Contributions. To this end, we presentMMAU-Pro, a novel benchmark consisting of 5,305 expert-annotated in- stances designed to evaluate 49 distinct auditory intelli- arXiv:2508.13992v1 [eess.AS] 19 Aug 2025 

Audio Transcript: What is the packing efﬁciency , in percentage, of a solid where Atom X occupies the face-centered cubic lattice sites as well as alternate tetrahedral voids of the same lattice? Question: Choose the correct option that answers the question in the audio from the options given below. Options: (A) 25% (B) 35% (C) 55% (D) 75% Answer: (B) 35% Voice STEM QA Question: What raag is this bandish composed in? Options: (A) Bhimpalasi (B) Kannada (C) Durga (D) Malkaunse (E) Bhairavi (F) Yaman Kalyan Answer: (C) Durga Multicultural Music Question: What trend can be observed in the weight of the cloths thrown in the audio? Options: (A) Increasing (B) Decreasing (C) Remains constant (D) None of these options Answer: (A) Increasing Perceptual Skills: Acoustic Trend Estimation Reasoning Skills: Temporal Reasoning Sound Question: Can you guess the singer in this song? Options: (A) Jef f Beck (B) Tenacious B (C) Jimmy Hendricks (D) Jack Black Answer: (D) Jack Black Perceptual Skills: Timbre Perception and Instrument Recognition Reasoning Skills: Musicological Knowledge Music Question: What ef fect needs to be applied to the ﬁrst recording to achieve sound of the second recording? Options: (A) echo (B) distortion (C) phaser (D) reverb Answer: (D) reverb Multi-Audio Audio Transcript: Instruction: Explain what's happening in this audio. Your answer must contain a title, wrapped in double angular brackets, such as <<poem of joy>>. Question: What effect needs to be applied to the ﬁrst recording to achieve sound of the second recording? Correct Answer: <<Harmonica's Ascending and Descending Scale>> This audio clip features a harmonica playing the C major scale. The musician ﬁrst plays the scale in an ascending order, moving from the lowest note to the highest. Wrong Answer: This is an audio clip of a person playing the C major scale on a harmonica, ﬁrst ascending and then descending. Multimodal Instruction Following Question: What did the winning team get at the end of the game? Options: (A) They choose the next vacation destination (B) The other team has to get rid of their rooster (C) They win the other team’s apartment (D) The game ends in a tie and nothing changes \ Answer: They win the other team’s apartment Question: In the audio with roughly the same phrase being repeated, explain how the dif ferent tone effects the meaning of each of the 4 phrases and in what order they occur. Options: (A) Bored → enthusiastic → questioning → angry (B) Cheerful → playful → serious → stern (C) Sarcastic → sincere → doubtful → irritated (D) genuine → sarcastic → questioning → frustrated. Answer: (D) He can remove 0 bones Perceptual Skills: Speech Activity, Turn-Taking and Overlap Detection Reasoning Skills: Quantitative Reasoning (Counting/Arithmetic Comparison) Long Audio Speech Question: Answer the question in the audio. Options: (A) It sounds like this decision carries a lot of weight... (B) Perhaps the best approach is to systematically ... (C) Your tranquil state suggests you have a high degree of mental clarity right now. This is an excellent time to trust your judgment, as it's likely unclouded by.... (D) Making major decisions during emotional peaks,.. Answer: Your tranquil state suggests you have a high degree of mental clarity right now. This is an excellent time to trust your judgment, as it's likely unclouded by emotional turmoil. Voice QA Question: Who's order does the waiter take ﬁrst? Options: (A) The person to the left of the mic holder (B) The person to the right of the mic holder (C) The person in front of the mic holder Answer: (A) The person to the left of the mic holder Spatial QA Question: What is hyper-foreignism with respect to pronunciation according to the clip? Answer: When a speaker changes the way they say a word to sound more like that of the stereotype they hold for a foreign language Open-ended QA Question: Which of the following songs is made according to the speaker? Options: (A) Not Like Us (B) Star Biy (C) All the stars (D) HUMBLE Answer: (D) HUMBLE Speech-Sound-Music Mix Figure 1: Overview of the MMAU-Pro benchmark. MMAU-Pro provides comprehensive coverage across all three core au- dio domains-speech, sound, and music-and extends evaluation to their mixtures. It further includes multi-audio reasoning, long-form audio (up to 10 minutes), voice-chat QA, spatial audio understanding, open-ended QA, and multimodal instruction following, offering a broad and realistic assessment of audio intelligence. gence skills spanning speech, environmental sounds, and music. MMAU-Pro presents challenges overlooked by prior benchmarks, including long-form audio understanding (up to 10 minutes), reasoning across multiple clips, spatial audio perception, multicultural music interpretation, instruction- following abilities, etc. All questions are crafted to require deliberate multi-hop reasoning and include a balanced mix of multiple-choice and open-ended formats. To address the shortcomings of existing evaluation methodologies, we fur- ther propose a retrieval-based evaluation framework that en- ables more robust and reliable assessment. By emphasiz- ing realistic and demanding auditory tasks, MMAU-Pro pro- vides a comprehensive testbed to accelerate the development of auditory intelligence in multimodal AI systems. To sum- marize, our main contributions are: • We introduce MMAU-Pro, the most comprehensive benchmark to date for evaluating auditory intelligence. It comprises 5,305 expert-annotated question–answer pairs spanning 49 distinct skills across speech, environmen- tal sounds, music, and their mixtures. MMAU-Pro in- troduces novel challenges, including spatial audio rea- soning, multi-clip audio reasoning, voice–chat compre- hension, and tasks requiring prosodic, world-knowledge, and STEM-based reasoning. All audio samples are drawn from the wild, with durations up to ten minutes, signif- icantly surpassing the short clips typical of prior bench- marks where current models are near-saturated. • We benchmark over 15 open-source and proprietary mul- timodal LLMs on MMAU-Pro, finding that even the strongest models face substantial challenges. Gemini 2.5 Flash achieves only 59.2% accuracy; the best-performing fully open-source model, Audio Flamingo 3, reaches 51.7%; and the strongest open-weights omni model, Qwen2.5-Omni-7B-Instruct, achieves just 52.2%. • We provide an in-depth analysis of model responses, uncovering key failure modes in auditory perception and reasoning. These include shallow audio grounding, degradation in text-only and STEM reasoning, poor per- formance in multi-audio and spatial reasoning, and lim- ited understanding of multicultural music. Related Work Large Audio Language Models Recent advances in multimodal modeling have led to (L)ALMs-models that pair audio perception with (L)LMs to tackle complex audio tasks. Early systems such as Whis- per (Li et al. 2024a; Peng et al. 2023) and CLAP (Wu et al. 2023; Elizalde et al. 2023; Elizalde, Deshmukh, and Wang 2024) focused on foundational tasks like transcription, cap- tioning, and retrieval, but struggled with reasoning-centric challenges. More recent models-GAMA (Ghosh et al. 2024), Audio Flamingo (Ghosh et al. 2025b; Goel et al. 2025), Mellow (Deshmukh et al. 2025), Phi-4MM (Abouelenin et al. 2025) Qwen2-Audio (Chu et al. 2024), and Audio- PALM (Rubenstein et al. 2023) proposed improved archi- 

Reasoning Skills Distribution Perceptual Skills Distribution Reasoning Skills Perceptual Skills - Speaker Role & Relationship Inference - Speaker Characteristics - Quantitative Reasoning (Counting/Arithmetic) - Language/Accent Identification - Information Extraction - Prosody Detection - Contextual/Causal Scenario Reasoning - Lexical & Phrase-Level Recognition - Temporal & Ordering Reasoning - Speaker Demographics - World Knowledge Integration - Paralinguistic/Emotion Recognition - Mathematical & Logical Reasoning - Speech Activity & Turn-Taking - other (Speech) - Audio Quality & Artifacts - Acoustic Scene Reasoning - Other (Speech) - Action-Based Reasoning - Acoustic Source Characterization - Procedural Reasoning - Acoustic Trend Estimation - Quantitative Reasoning - Eco-Acoustic Knowledge - Temporal Reasoning - Harmony Perception & Analysis - Comparative Reasoning - Pitch & Melody Perception - Emotion Interpretation - Rhythmic Pattern & Tempo Recognition - Lyrical Content Analysis - Spatial Sound Perception - Musicological Knowledge Artist/Speaker Identification - Quantitative Reasoning Texture & Dynamic Range Perception - Structure & Form Analysis Timbre Perception & Instrument Recognition - Style & Genre Recognition - Auditory Source Separation - Audio Perspective Inference - Material Sound Recognition - 
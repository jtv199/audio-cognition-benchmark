Source: Bregman_1990_ASA_Ch8_Conclusions.pdf
First 2000 words extracted
================================================================================

Chapter 8 Summary and Conclusions: What We Do and Do Not Know about Auditory Scene Analysis Summary of Previous Chapters This chapter presents my conclusions about what we do and do not know about auditory scene analysis at present. The sequence of topics exactly follows that of the previous chapters, so ifa point is not clear here, or if fuller details are wanted, the reader should have no difficul- ty in finding the corresponding material in the earlier discussion. In this chapter I present no references to the experiments on which the conclusions are based. The interested reader can look for them in the earlier chapters. Sometimes I have not undertaken to define a techni- cal word here. In such cases, a rough definition can be found in the glossary at the end of the book. Primitive Auditory Scene Analysis The problem of scene analysis is this: Although we need to build separate mental descriptions of the different sound-producing events in our environments, the pattern of acoustic energy that is received by our ears is a mixture of the effects of the different events. lt appears that our auditory systems solve the problem in two ways, by the use of primitive processes of auditory grouping and by governing the listening process by schemas that incorporate our knowledge of familiar sounds. This book has been mainly about the primitive pro- cess, although it has tried to discover whether the effects of the two kinds of processes can be distinguished from each other. I shall begin this summary by talking about the primitive process. The primitive process of scene analysis seems to employ a strategy of first breaking down the incoming array of energy into a large number of separate analyses. These are local to particular moments of time and particular frequency regions in the acoustic spectrum. Each region is described in terms of its intensity, its fluctuation pattern, the direction of frequency transitions in it, an estimate of where the sound is coming from in space, and perhaps other features. After This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444587/9780262269209_cah.pdf by UNIV OF MELBOURNE user on 08 December 2025 

642Chapter 8 these numerous separate analyses have been done, the auditory sys- tem has the problem of deciding how to group them so that each group has been derived from the same environmental event. The grouping has to be done in two dimensions (at least), across time and across the spectrum. I have called the temporal grouping "sequential integration" and have referred to the other one as "simultaneous in- tegration." The chapters in this volume have been laid out according to this division. However, I have pointed out that the two forms of grouping often operate in conjunction to solve the problem. Sequential Integration: Auditory Stream Segregation Sequential integration is visible in a number of contexts, but a popu- lar stimulus pattern for studying it has been the one that gives rise to auditory stream segregation. This occurs when a sequence of tones jumps rapidly up and down between different frequency regions. The simplest case is a rapid repeated alternation of a high and a low tone. If the alternation is fast enough and the frequency separation great enough, listeners will not experience a single stream of tones alternat- ing in pitch, but will perceive two streams of tones, one consisting of repetitions of the lower tone and the other consisting of repetitions of the higher one. When two streams are heard, the listener has the im- pression of two different sources of sound, one high pitched and the other low, whose tones happen to occur at about the same time. In more complex patterns, where a number of higher tones of slightly different frequencies are interleaved with a number of lower tones, listeners will still hear two streams, but this time each stream will have a melodic pattern that is restricted to the tones of that stream. One sort of stimulus that has been used is a short repeating loop of tones. The tones are chosen from two different frequency regions, one high and one low. The properties of the tones have been varied and the effects on stream segregation observed. Another form of stimulus has been a tune or other short tonal pat- tern interleaved with distractor tones. The frequency relations be- tween the distractor and the relevant tones have been varied. When the two sets of tones are in the same frequency region, the tune dis- appears into a pattern formed out of all the tones, but if they are in two nonoverlapping frequency regions, the tune is readily heard as a separate stream. This sort of stimulus has been used to study primi- tive segregation but is more suited for the study of schema-based segregation. Auditory stream segregation has been known by musicians since the Baroque period, when it was used to produce the impression of This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444587/9780262269209_cah.pdf by UNIV OF MELBOURNE user on 08 December 2025 

Summary and Conclusions643 two lines of melody even though the instrument playing the sequence could produce only one note at a time. This could be done by having the instrument rapidly alternate between a higher and a lower melo- dic line. Factors Influencing Stream SegregationThe most important influences on the segregation of the streams are the rate of the tonal sequence and the frequency separation between the two subsets of tones that are interleaved. As the subsets are moved further apart in frequency, the segregation increases and it becomes harder and harder for a listener to hear the entire sequence as a single stream of sound. (A logarithmic scale seems to be one that reflects the segregability of the frequencies.) Furthermore the segregation increases when the se- quence goes faster. As a consequence of these facts, the effects of frequency separation and time can be traded off against one another. As the frequency separationincreases,the sequence must be slowed down if the listener is to be able to experience all the tones as part of a single, coherent stream of sound. However, the effects of frequency separation and speed depend on what the listeners are trying to do. If they are trying to hear all the tones as part of a single sequence, the effects are as I have just de- scribed them. But if they are trying to focus their attention on the tones of just one of the streams, the effects of frequency separation and speed are different. The frequency separation of the high from the low tones need only exceed some small amount (a few semitones in the case of two alternating tones) before the target sequence can be followed by attention. Further increases in separation do not increase the segregation and the capacity to follow the selected stream is vir- tually unaffected by the speed of the sequence. Because of the differ- ence in the effects when listeners are trying to hear coherence or seg- regation, I have proposed that two different factors are at work. One, primitive segregation, is affected by the rate and the frequency separa- tion. The other, schema-based segregation that involves attention, is used for focusing on one of the streams. The attention of the listener can always be directed toward a narrow frequency range when re- quired by the task. Beyond the minimum frequency separation that it requires so as not to confuse the notes of the stream that it is follow- ing with the tones of other streams, the attentional process is un- affected by the separation between the frequencies. We know that the result of different speeds comes from the fact that certain temporal intervals have been affected. But we do not know exactly which ones, lithe effect is based on bringing the tones from the same frequency range closer together in time, we would This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444587/9780262269209_cah.pdf by UNIV OF MELBOURNE user on 08 December 2025 

644Chapter 8 expect that the time interval between the end of one tone and the beginning of another in the same range would be the important one. Yet some evidence suggests that it is the separation of the onsets of the two that is important. There is another question too. Which is impor- tant: the interval between successive tones in the same frequency range or that between successive ones in the up-and-down sequence? Since most studies use sequences in which all tones and intertone silences are the same length, it is impossible to tell which of these in- tervals is the critical one. It appears that the stream-forming process behaves in a manner analogous to the Gestalt principle of grouping by proximity. The high tones tend to group with other high ones if brought close to them in time by the speeding up of the sequence. When we talk about the proximity of tones or sounds in frequency or in time, we are implying that the stream of sound is composed of discrete units. But what about cases in which the sound is more con- tinuous? Where are the units? It appears as though there is a unit- forming process that is sensitive to discontinuities in the sound, parti- cularly to sudden rises in intensity, and that creates unit boundaries when such discontinuities occur. Units can occur at different time scales and smaller units can be embedded in larger ones. When the sequence is speeded up, the changes that signal the smaller units may be missed by the auditory system, and other changes, too gradual to form units at the slower speed, may now be sudden enough to con- trol the formation of units. The units, once formed by these processes, can form groups with other similar ones. Similarity is determined by analyses that are ap- plied to the units once they are formed. For example, suppose there is a glide in frequency, bounded by a rise and a fall in intensity. Be- tween these boundaries, the change in frequency may be measured by the auditory system and assigned to the unit as one of its properties. This frequency-gliding unit will prefer to group with other ones whose frequency change has the same slope and which are in the same frequency region. One of the similarities that affects the grouping of tones is their location in space. Engineers working on the automatic segregation of concurrent sounds have used spatial separation as a uniquely powerful way of determining whether the sounds have come from the same physical event (usually a talker). Humans use spatial origin too, but do not assign such an overwhelming role to it. They can do quite well at segregating more than one stream of sound coming from a single point in space, for example, from a single loudspeaker. This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444587/9780262269209_cah.pdf by UNIV OF MELBOURNE user on 08 December 2025 

Summary and Conclusions645 Primitive scene analysis tends to group sounds that come from the same point in space and to segregate those that come from different places. As a consequence, if two sounds, different in frequency, are alternated between the ears, they will not form a single coherent stream. The frequency separation, the rate, and the spatial separation combine to influence the segregation. Spatial differences seem to have their strongest effects on segregation when they are combined with other differences between the sounds. Illusions can be created by set- ting up a competition between the tendency to group sounds by their frequency similarity and by their spatial similarity. An example is Diana Deutsch's scale illusion. When speech is rapidly switched back and forth between the ears, it is hard to follow. One reason is that when the switch occurs, it pro- duces a sudden rise in intensity in one ear and a sudden drop in the other. If the listener simply combined the two changes there would be no net 
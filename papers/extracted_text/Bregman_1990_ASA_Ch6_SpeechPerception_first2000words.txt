Source: Bregman_1990_ASA_Ch6_SpeechPerception.pdf
First 2000 words extracted
================================================================================

Chapter 6 Auditory Organization in Speech Perception I now want to examine the role of the primitive scene-analysis pro- cesses in the perception of speech. As the discussion proceeds, however, we will see that the contribution of primitive processes is obscured by the contribution of speech schemas. I described some general properties of schemas in chapter 4. Among them was the property of being able to extract what is needed from mixtures. Since both primitive grouping and schema-based grouping operate at the same time, it will be difficult to know what is primitive and what is not. The strategy that I will follow is that when the organizational processes are the same in speech as in simpler signals, I will assume that they derive from primitive processes, whereas when particular capabilities for perceptual isolation are found in speech, I will assume that these are schema-based. However, I will not take any position on which schemas are innate and which are learned. In 1953, Colin Cherry, a British researcher working at the Mas- sachusetts Institute of Technology, reported research on what he called "the cocktail party problem."665 How can we select the voice of a particular talker in an environment in which there are many others speaking at the same time? He did a number of experiments in which a person, listening over headphones, had to report what a recorded voice was saying when it was accompanied by a second re- cording made by the same talker. He found that two factors affected the ease with which this could be done. The first was whether the recordings were sent to the same headphone or to the opposite one. It was much easier to follow one voice when the other was sent to the opposite ear. The second was that when the two recordings were sent to the same ear, it was easier to follow one of them when the next part of what it was saying was predictable from the pre- vious part. When this predictability decreased, the listener often switched attention to the other recording. The act of segregating and following one of the two recordings was called "filtering." This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444585/9780262269209_caf.pdf by UNIV OF MELBOURNE user on 08 December 2025 

530Chapter 6 Cherry proposed other factors that would make it easier. He men- tioned the assistance offered by cues such as differences in the quality of the two voices, differences in their mean speeds or mean pitches, differing accents, and even visual cues such as lip reading. Other re- searchers showed that when Cherry had made segregation easy by sending the messages to different ears, it was not the fact that each ear got only one signal that was important, but that the perceived spatial origins of the two sounds were different.666 The same researchers showed that high-pass filtering one message above 1,600 Hz and low- pass filtering the other below that frequency also allowed an easy segregation of the messages. Cherry mentioned several factors that he thought would help us to segregate voices. Some were raw physical qualities, but others had to do with the ability of the listener to predict the next moment of speech from the previous one. It is not clear whether this ability to predict is really used in segregating the message from others at the basic scene-analysis level or is only used in matching the sound to memories of words, phrases, and so on. However, there is no doubt that it is governed by the listener's knowledge of speech and lan- guagea property that labels it as schema-based integration and therefore excludes it from the present discussion. I want to focus on an examination of the role of primitive scene-analysis processes in the separation of speech sounds. A great number of theories were invoked to account for the selec- tive attention demonstrated by Cherry. However, they were all simi- lar in certain ways. They all mentioned that the physical properties of one of the voices could be used by the listener's attention to select that voice, and they all seemed to presuppose that factors such as location, pitch, timbre, and loudness were simple and easily available. Yet if we made a stereophonic tape recording at the position of the listener's ears at a cocktail party and then made a spectrogram from each chan- nel of that recording, the resulting pictures would look very unlike the patterns that phoneticians have come to associate with speech sounds. Nor would the pitch and timbre of individual speakers' voices or their locations be obvious from an inspection of the pic- tures. Yet these were the "physical factors" that were assumed to be the strongest bases on which the process of attention could separate the mixture and track the desired target. It is clear that we must introduce scene analysis as a preliminary process that groups the low-level properties that the auditory system extracts and builds separate mental descriptions of individual voices or nonvocal sounds, each with its own location, timbre, pitch, and so This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444585/9780262269209_caf.pdf by UNIV OF MELBOURNE user on 08 December 2025 

Auditory Organization in Speech Perception531 on. Only then does it make sense to say that our attention can select a voice on the basis of one of these qualities. What I am arguing is that factors such as pitch, timbre, and location are the results of segregating the mixture, not the causes of its segrega- tion. "But," one might reply, "is it not true that a particular voice has its own spatial location, fundamental frequency, and so on, and that it is these properties that allow us to select it from the mixture?" The apparent contradiction, as in other cases that we have examined, is resolved by drawing a distinction between the physical and psycholog- ical realms. It is true, for example, that every signal at the cocktail party has a physical place of origin, but this does not guarantee that this origin is represented in the perceptual domain or that all the in- formation that has been received from that origin will contribute to the appropriate mental description. For example, in certain illusions, the evidence received from one part of space is assigned to a percep- tual sound that is heard as being at a different location. A more exact account of causes and effects would be to say that the physical place of origin may be responsible for some physical prop- erties that the received signal has, and if this evidence is used correct- ly, the perceptual image of the sound will have a mentally represented place that corresponds to the physical place and a set of perceived qualities that adequately represent the physical properties of the source. Until this is accomplished, however, there is no mentally in- tegrated sound with its own location label that can be selected by higher mental processes. If we look at the spectrogram of a mixture of sounds such as figure 1.4 of chapter 1, we see that there are two dimensions on which acoustic information must be grouped. The first is over time, to re- construct the temporal pattern of the sound. The second is over the spectrum. Without the partitioning of evidence that is accomplished by such grouping, the evidence for particular speech sounds can be invisible. Christopher Darwin has given a nice example to show that the array of sound will be heard as having' the phonetic patterns that we are familiar with only after it is partitioned into streams: Knowledge about the properties of phonetic categories [such as the phoneme "b"] must be represented by properties of the sound produced by a single...speaker. Yet properties that are apparent in the raw waveform are not specific to a single speaker or sound source; they are properties that are due to whatever sound sources are present at the time. For example, the silence necessary to cue an inter-vocalic stop consonant [such as the "b" This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444585/9780262269209_caf.pdf by UNIV OF MELBOURNE user on 08 December 2025 

532Chapter 6 in the word "about"} is silence of a single sound source; there may be no actual silence present in the waveform.7 We want to understand the segregation of speech sounds from one another and from other sounds for many practical as well as theoret- ical reasons. For example, current computer programs that recognize human speech are seriously disrupted if other speech or nonspeech sounds are mixed with the speech that must be recognized. Some attempts have been made to utilize an evidence-partitioning process that is modeled on the one that is used by the human auditory system. Although this approach is in its infancy and has not yet implemented all the heuristics that have been described in the earlier chapters of this book, it has met with some limited success. I will describe a number of these approaches in this chapter. Sequential Organization of Speech Sounds In this section we will look at the sequential integration of the speech signal. The rapid sequence of different types of sounds coming from a particular talker has to be held together into a single stream and, at the same time, must not connect up sequentially with the sounds coming from a different talker. At the very microscopic level, even the identification of many of the speech sounds themselves depends on the relevant information being assigned to the same perceptual stream. For example, in the phrase "say chop", there is a brief silence before the "ch" noise burst that tells the listener that it is "ch" rather than "sh". The silence tells the listener that there has been a closing off of the air flow of the talker's voice. Yet the listener must interpret the silence as occurring between speech sounds made by the same voice. If one voice stops and another one starts, this does not signal a closure. An experiment done by Michael Dorman and his colleagues shows that the heuristics of scene analysis can contribute to the correct interpretation.668 If the pitch of the voice changes suddenly from that of a male to that of a female between the two words, the perception of "chop" does not occur. Listeners will hear "shop". The dip in intensity signals "ch" only when it is interpreted as a within-stream dip and not the product of an accidental concatenation of two distinct sound sources. Sequential integration also has to operate on a longer time scale. In the early observations by Cherry, in which a person was asked to shadow one verbal message while ignoring a second, whenever the acoustical basis for segregation was not good (for example, when the two messages were spoken by the same talker and not spatially segre- This is a portion of the eBook at doi:10.7551/mitpress/1486.001.0001 Downloaded from http://direct.mit.edu/books/monograph/chapter-pdf/2444585/9780262269209_caf.pdf by UNIV OF MELBOURNE user on 08 December 2025 

Auditory Organization in Speech Perception533 gated) the listener would frequently switch from tracking one mes- sage to the other. The problem did not seem to be one of segregating the simultaneous sounds; otherwise the listener would not have been able to track either message. It seemed, instead, to be a problem of the sequential grouping of the words from a single talker. The need for sequential integration of speech sounds introduces a serious problem for primitive scene analysis. Speech is a succession of qualitatively different sounds. For example, an "s" is a type of noise burst whereas an "o" is a type of tone with a harmonic structure. We know that a noise burst will sequentially segregate from a tone; so why do the sounds of the speech stream hold together? The basic building blocks of speech are usually described as phonemes, which are divided into vowels and consonants. For our rough purposes here, phonemes can be thought of as the simple sounds that are indicated by single letters or 
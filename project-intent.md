# Audio Cognition Benchmark - Project Overview

## Executive Summary

This project develops a comprehensive benchmark to evaluate Audio Large Language Models (AudioLLMs) on **higher-order reasoning tasks**, moving beyond simple transcription and classification. The core innovation is bridging the gap between what AI models currently excel at (**Perception** - identifying "dog bark") and what they struggle with (**Reasoning** - inferring "The dog is barking behind a wall, so I cannot see it").

**Current Status**: Phase 1 - Literature Review & Taxonomy Mapping (90% Complete)

**Repository**: https://github.com/jtv199/audio-cognition-benchmark

---

## Project Goals

### Primary Objective
Define the theoretical boundaries of "Human Auditory Capability" to construct a valid evaluation benchmark for "Audio Reasoning" in AI models by:

1. **Referencing multiple cognitive frameworks** from psychology and neuroscience to identify the full spectrum of auditory cognition tasks
2. **Mapping these tasks** across existing AI audio benchmarks (AIR-Bench, AudioBench, MMAU-Pro, WavCaps)
3. **Identifying gaps** in current benchmark coverage that represent missing capabilities in AI evaluation
4. **Establishing a systematic taxonomy** that can guide future benchmark development

### Key Research Question
*"How do different scientific fields categorize the hierarchy of human hearing, and what does this reveal about missing capabilities in current AI audio evaluation?"*

---
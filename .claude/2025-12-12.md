# Research Session: December 12, 2025

## Topic: Cognitive Taxonomies for Audio Cognition from Baldwin (2012)

**Source**: *Auditory Cognition and Human Performance* by Carryl L. Baldwin (2012), CRC Press

**Chapters Reviewed**:
- Chapter 4: Auditory Cognition - The Role of Attention and Cognition in Auditory Processing
- Chapter 5: Theories and Techniques of Mental Workload Assessment
- Chapter 6: Auditory Tasks in Cognitive Research

---

## Key Taxonomies Identified

### 1. Baddeley's Working Memory Model

**Question it answers**: *How is information held and manipulated in the mind?*

```
┌─────────────────────────────────────┐
│         CENTRAL EXECUTIVE           │
│    (attention control, switching,   │
│     coordination, inhibition)       │
└───────────────┬─────────────────────┘
                │
        ┌───────┴───────┐
        ▼               ▼
┌───────────────┐ ┌───────────────┐
│ PHONOLOGICAL  │ │  VISUOSPATIAL │
│     LOOP      │ │   SKETCHPAD   │
│ ┌───────────┐ │ │               │
│ │  Store    │ │ │  (visual &    │
│ │  (~2 sec) │ │ │   spatial     │
│ └─────┬─────┘ │ │   imagery)    │
│       ▲       │ │               │
│ ┌─────┴─────┐ │ │               │
│ │ Rehearsal │ │ │               │
│ └───────────┘ │ │               │
└───────────────┘ └───────────────┘
     VERBAL           SPATIAL
```

**Key Quote**:
> "Baddeley's three-component working memory system consists of a **central executive**, attentional controlling system and **two slave systems**. The slave systems consist of a **visuospatial sketch pad** for processing and manipulating visual images and a **phonological or articulatory loop** for manipulation of speech-based information."

**Phonological Loop Details**:
> "Baddeley (1998) described the phonological loop as consisting of **two components**. The first is a **phonological store** capable of holding information for up to 2 s. The second component is an **articulatory control process** responsible for subvocal rehearsal."

#### Tasks Mapped to Baddeley Components

| Component | Example Tasks |
|-----------|---------------|
| **Central Executive** | Dual-task coordination, Task switching, Stroop, Wisconsin Card Sorting, Complex span |
| **Phonological Store** | Digit span forward, Word span, Non-word repetition, Suffix effect |
| **Articulatory Rehearsal** | Articulatory suppression, Word length effect, Reading span |
| **Visuospatial Sketchpad** | Corsi blocks, Mental rotation, Visual pattern span, Brooks matrix |

---

### 2. Wickens' Multiple Resource Theory (MRT)

**Question it answers**: *Why do some task combinations interfere more than others?*

**Key Quote**:
> "According to MRT, tasks can compete for common mechanisms with functionally separate 'reservoirs' or pools of attentional capacity in **three ways**: First, tasks may compete for the same **modality of input** (visual vs. auditory) or **response** (vocal vs. manual). Second, tasks can compete for the same **stage of processing** (perceptual, central, or response execution). Third, tasks may compete for the same **code** of perceptual or central processing (verbal vs. spatial)."

```
WICKENS' MRT DIMENSIONS
│
├── INPUT MODALITY
│   ├── Visual
│   └── Auditory
│
├── OUTPUT MODALITY
│   ├── Manual (hands)
│   └── Vocal (speech)
│
├── PROCESSING CODE
│   ├── Verbal (language, text, speech)
│   └── Spatial (locations, movements)
│
└── PROCESSING STAGE
    ├── Perceptual (encoding input)
    ├── Central (thinking, deciding)
    └── Response (executing output)
```

**Key Prediction**:
> "cross-modal (visual-auditory) tasks were time-shared more efficiently than intramodal (visual-visual or auditory-auditory) tasks."

**Code Matters More Than Modality Sometimes**:
> "it is more difficult to **read text and listen to someone talking** than it is to extract information from a spatial display while listening to someone talk. **Both text and speech rely on a verbal processing code** and therefore are more likely to interfere."

---

### 3. Processing Stages Pipeline

**Key Quote**:
> "the sound stimulus will be initially coded in **acoustic format** and then will progress to a **lexical** and then **semantic code** as processing continues."

```
ACOUSTIC → PHONOLOGICAL → LEXICAL → SEMANTIC
```

| Stage | What's Processed | Example Task |
|-------|------------------|--------------|
| Acoustic | Raw features (frequency, amplitude) | "Is this tone high or low?" |
| Phonological | Speech sounds, syllables | "Does this rhyme with 'cat'?" |
| Lexical | Word recognition | "Is 'blick' a real word?" |
| Semantic | Meaning, context | "What does this sentence mean?" |

---

### 4. Attention Filter Theories

**Key Quote**:
> "In a broad sense, this history can be divided into **three primary phases**: (a) **filter theories**, (b) **capacity or resource theories**, and (c) **cognitive neuroscience models**."

| Model | Filter Location | Description |
|-------|-----------------|-------------|
| **Broadbent (Early Selection)** | Pre-attentive sensory | Filter occurs in preattentive sensory processing |
| **Treisman (Attenuation)** | Graded | Unattended info attenuated, not blocked |
| **Deutsch & Deutsch (Late Selection)** | After LTM | All info reaches LTM; bottleneck at response selection |

---

### 5. Echoic Memory (Two-Store Model)

**Key Quote**:
> "Current opinion on the topic of auditory sensory memory tends to suggest that **two forms of precategorical acoustic storage exist**."

| Store | Duration | Location |
|-------|----------|----------|
| **Short-term auditory store** | 200-300 ms | Primary auditory cortex |
| **Long-term auditory store (Echoic)** | 2-4 seconds | Association cortex |

---

### 6. Bottom-Up vs Top-Down Processing

**Key Quotes**:
> "**Bottom-up processing** essentially refers to the influence of the direct stimulus input... often referred to as **data-driven**."

> "**Top-down processing** refers to the influence of existing memories and knowledge structures (such as the use of context)... often referred to as **conceptually driven**."

---

### 7. Additional Taxonomies (from literature)

| Taxonomy | Dimension | Use For |
|----------|-----------|---------|
| **Automatic vs Controlled** (Schneider & Shiffrin) | Effort required | Expertise & learning effects |
| **Attention Types** | Selective/Divided/Sustained | Attention task classification |
| **Bregman's ASA** | Primitive vs Schema-based | Sound segregation tasks |
| **Gaver's Listening Modes** | Musical vs Everyday | Listening goal classification |

---

## Chapter 6: Auditory Tasks in Cognitive Research

### Task Categories Identified

1. **Dichotic Listening Tasks** - Selective attention, cerebral dominance
2. **Encoding & Retrieval Tasks** - Memory processes
3. **Working Memory Tasks** - Listening span, n-back
4. **Psychological Refractory Period (PRP)** - Dual-task bottleneck
5. **Mental Workload Assessment** - Secondary tasks, ERP indices
6. **Neuropsychological Tests** - PASAT, RAVLT, Halstead-Reitan
7. **Neurophysiological Probes** - PPI, MMN, ERPs

### Specific Tasks Mapped

| Task | Category | Real-World Example |
|------|----------|-------------------|
| Dichotic Listening | Selective Attention | "Follow one voice at a cocktail party" |
| Listening Span | Working Memory | "Judge sentences AND remember last words" |
| Auditory n-Back | Working Memory | "Did this word match the one 2 items back?" |
| PASAT | Neuropsychological | "Add consecutive numbers: 5,7,3,9 → 12,10,12" |
| RAVLT | Neuropsychological | "Learn 15 words over 5 trials, recall after interference" |
| Auditory Oddball | ERP/Workload | "Count the rare 'ding' among repetitive 'dongs'" |

---

## Application to Benchmark Tasks

### Best-Fit Taxonomies for Audio Benchmarks

| Taxonomy | Applicability | Why |
|----------|---------------|-----|
| **Processing Stages** | ⭐⭐⭐⭐⭐ | Perfect fit - tasks vary by depth |
| **Bottom-Up / Top-Down** | ⭐⭐⭐⭐⭐ | Maps to Perceptual/Reasoning split |
| **Gaver's Modes** | ⭐⭐⭐⭐ | Maps to Speech/Sound/Music domains |
| **Automatic / Controlled** | ⭐⭐⭐⭐ | Predicts task difficulty |
| **Bregman ASA** | ⭐⭐⭐ | Multi-source tasks only |
| **Baddeley WM** | ⭐⭐ | Long-form/memory tasks only |
| **Wickens MRT** | ⭐ | Not applicable - single-modality |

### Recommended Combined Taxonomy

```
TASK CLASSIFICATION
│
├── DOMAIN (Gaver)
│   ├── Speech
│   ├── Sound (Everyday)
│   └── Music
│
├── PROCESSING DEPTH
│   ├── Acoustic (features)
│   ├── Phonological/Structural (patterns)
│   ├── Lexical/Identity (recognition)
│   └── Semantic/Pragmatic (meaning)
│
├── PROCESSING DIRECTION
│   ├── Bottom-Up (data-driven)
│   ├── Top-Down (knowledge-driven)
│   └── Interactive (both)
│
└── COGNITIVE DEMAND
    ├── Perceptual (automatic, fast)
    └── Reasoning (controlled, effortful)
```

---

## Key Insights

1. **Baddeley and Wickens complement each other**: Baddeley explains memory architecture; Wickens explains task interference patterns.

2. **Tasks recruit multiple components**: A single task often spans multiple WM components (e.g., listening span = Central Executive + Phonological Loop).

3. **Processing Stages Pipeline** is highly applicable to classifying audio tasks by depth of processing required.

4. **The MMAU-Pro benchmark** already captures Perceptual/Reasoning split (≈ Bottom-Up/Top-Down) and Domain split (≈ Gaver's Modes).

5. **Missing from current benchmarks**: Explicit Baddeley-style memory load manipulation and Wickens-style cross-modal dual-task paradigms.

---

## Email Draft Sent to Supervisor

**Key points communicated:**
1. Obtained Baldwin (2012) through friend at Monash
2. Proposed Processing Depth + Processing Direction taxonomy
3. Noted MMAU-Pro already has Perceptual/Reasoning split (= Processing Direction)
4. Asked clarifying question about taxonomy purpose (gap identification vs human function mapping)
5. Noted neuropsychological tests (ERP, brain stem) don't translate to AI evaluation
6. Proposed next steps: map MMAU-Pro skills to taxonomy, find uncovered datasets

---

## Out of Scope (Confirmed)

Based on Baldwin's book and project focus:

| Out of Scope | Why |
|--------------|-----|
| ERP/Brain imaging tasks | Measures neural activity, not behavior |
| Audiometric tests (pure tone thresholds) | Clinical hearing assessment |
| Binaural localization | Requires spatial audio hardware |
| Music notation/theory | Visual/symbolic, not audio cognition |
| Speech production | Output, not input processing |

---

## Next Steps

1. **Map MMAU-Pro's 38 skills** to Processing Depth × Processing Direction taxonomy
2. **Identify gaps** where coverage is weak
3. **Find datasets** for under-covered areas
4. **Await supervisor feedback** on taxonomy purpose clarification

---

## Files Referenced

- `/papers/extracted-chapters/Chapter_12.md` (Chapter 4)
- `/papers/extracted-chapters/Chapter_13.md` (Chapter 5)
- `/papers/extracted-chapters/Chapter_14.md` (Chapter 6)
- `/output/benchmark-tasks.md`

---

*Session conducted with Claude Opus 4.5*


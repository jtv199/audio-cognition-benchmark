# Research Session: December 13, 2025

## Topic: Clinical Auditory Tests Gap Analysis (CAB vs MMAU-Pro)

**Focus**: Cross-referencing standardized clinical auditory cognition tests with MMAU-Pro benchmark coverage

---

## Key Activity

### CAB (Cognitive Auditory Benchmark) Task List

Identified 7 standardized clinical tests used for audio processing assessment in healthy adults. These tests have:
- Verified human baseline scores
- Stress cognitive mechanisms (working memory, selective attention, temporal resolution)
- Published normative data

### Gap Analysis Results

| Coverage Level | Count | Tasks |
|----------------|-------|-------|
| ✓ Well Covered | **0** | — |
| ⚠ Partially Covered | **3** | PASAT-AI, Dichotic Listening, QuickSIN |
| ✗ Not Covered | **4** | Time-Compressed Speech, Interrupted Speech, Reverberant Speech, Auditory 3-Back |

### Tests Analyzed

1. **PASAT-AI** (Paced Auditory Serial Addition) - 5/5 importance
   - Human baseline: ~44-65% at 2.0s pacing
   - Gap: No serial updating task with paced timing

2. **Forced-Left Dichotic Listening** - 5/5 importance
   - Human baseline: ~64-73% accuracy (CV syllables)
   - Gap: No explicit ear-inhibition/selective attention task

3. **QuickSIN** (Speech-in-Noise) - 5/5 importance
   - Human baseline: SNR-50 = +2.0 dB
   - Gap: No clinical SNR measurement

4. **Time-Compressed Speech** - 4/5 importance
   - Human baseline: Cliff at CR 0.4 (~2.5x speed)
   - Gap: Not covered at all

5. **Interrupted "Gated" Speech** - 4/5 importance
   - Human baseline: 4Hz notch effect (~50-86% accuracy)
   - Gap: No phonemic restoration task

6. **Reverberant Speech (RT60)** - 4/5 importance
   - Human baseline: <80% at RT60=1.0s
   - Gap: No explicit RT60 stress testing

7. **Auditory 3-Back** - 3/5 importance
   - Human baseline: ~73-77% accuracy
   - Gap: No explicit n-back paradigm

---

## Importance Scoring Criteria

Scores based on two factors:
1. **Cognitive Load**: How much the task stresses "reasoning/attention" vs. simple "hearing"
2. **AI Failure Potential**: How likely current Audio LLMs fail in non-human ways

---

## Key Insight

These clinical tests are **not used by existing AI audio benchmarks** (AIR-Bench, AudioBench, MMAU-Pro). They provide:
- Verified healthy adult norms (ground truth)
- Stress tests for cognitive mechanisms
- Potential differentiation for our benchmark

---

## Open Question for Ting

Requested clarification on "cognitive perspective" for task categorization:
- Sorting by difficulty = NOT cognitive
- Sorting by brain processing location (ventral/dorsal) = cognitive?
- Sorting by processing stages (Atkinson-Shiffrin) = cognitive?

---

## Files Generated

- `/output/cab-mmau-pro-coverage.md` - Full CAB task table with references
- GitHub: [benchmark-tasks.md](https://github.com/jtv199/audio-cognition-benchmark/blob/master/output/benchmark-tasks.md)

---

## References Added

1. Brooks et al. (2011) - PASAT norms
2. Tanaka et al. (2021) - Dichotic listening
3. Killion et al. (2004) - QuickSIN
4. Versfeld & Dreschler (2002) - Time-compressed speech
5. Shafiro et al. (2016) - Interrupted speech
6. Lee & Jeon (2022) - Reverberant speech
7. Miller et al. (2009) - N-back norms

---

*Session conducted with Claude Opus 4.5*


# Research Session: December 12, 2025

## Topic: Cognitive Taxonomies for Audio Cognition from Baldwin (2012)

**Source**: *Auditory Cognition and Human Performance* by Carryl L. Baldwin (2012), CRC Press

**Chapters Reviewed**:
- Chapter 4: Auditory Cognition - The Role of Attention and Cognition in Auditory Processing
- Chapter 5: Theories and Techniques of Mental Workload Assessment
- Chapter 6: Auditory Tasks in Cognitive Research

---

## Key Taxonomies Identified

### 1. Baddeley's Working Memory Model

**Question it answers**: *How is information held and manipulated in the mind?*

```
┌─────────────────────────────────────┐
│         CENTRAL EXECUTIVE           │
│    (attention control, switching,   │
│     coordination, inhibition)       │
└───────────────┬─────────────────────┘
                │
        ┌───────┴───────┐
        ▼               ▼
┌───────────────┐ ┌───────────────┐
│ PHONOLOGICAL  │ │  VISUOSPATIAL │
│     LOOP      │ │   SKETCHPAD   │
│ ┌───────────┐ │ │               │
│ │  Store    │ │ │  (visual &    │
│ │  (~2 sec) │ │ │   spatial     │
│ └─────┬─────┘ │ │   imagery)    │
│       ▲       │ │               │
│ ┌─────┴─────┐ │ │               │
│ │ Rehearsal │ │ │               │
│ └───────────┘ │ │               │
└───────────────┘ └───────────────┘
     VERBAL           SPATIAL
```

**Key Quote**:
> "Baddeley's three-component working memory system consists of a **central executive**, attentional controlling system and **two slave systems**. The slave systems consist of a **visuospatial sketch pad** for processing and manipulating visual images and a **phonological or articulatory loop** for manipulation of speech-based information."

**Note**: Baddeley applies better to multi-task studies and memory load tasks, less applicable to single-task classification like MMAU-Pro.

---

### 2. Wickens' Multiple Resource Theory (MRT)

**Question it answers**: *Why do some task combinations interfere more than others?*

```
WICKENS' MRT DIMENSIONS
│
├── INPUT MODALITY: Visual vs Auditory
├── OUTPUT MODALITY: Manual vs Vocal
├── PROCESSING CODE: Verbal vs Spatial
└── PROCESSING STAGE: Perceptual → Central → Response
```

**Key Quote**:
> "According to MRT, tasks can compete for common mechanisms with functionally separate 'reservoirs' or pools of attentional capacity in **three ways**: First, tasks may compete for the same **modality of input** (visual vs. auditory) or **response** (vocal vs. manual). Second, tasks can compete for the same **stage of processing** (perceptual, central, or response execution). Third, tasks may compete for the same **code** of perceptual or central processing (verbal vs. spatial)."

**Note**: MRT applies to dual-task interference (e.g., "can you do X while doing Y?"), not single-task classification.

---

## Proposed Taxonomy for MMAU-Pro Style Tasks

Based on the literature review, the most applicable framework for classifying single audio tasks:

```
TASK CLASSIFICATION

├── DOMAIN (Gaver, 1993)
│   ├── Speech
│   ├── Sound (Everyday)
│   └── Music

├── PROCESSING DEPTH (Baldwin, 2012, citing speech processing literature)
│   ├── Acoustic (features)
│   ├── Phonological/Structural (patterns)
│   ├── Lexical/Identity (recognition)
│   └── Semantic/Pragmatic (meaning)

├── PROCESSING DIRECTION (Norman & Bobrow, 1975)
│   ├── Bottom-Up (data-driven)
│   ├── Top-Down (knowledge-driven)
│   └── Interactive (both)

└── COGNITIVE DEMAND (Schneider & Shiffrin, 1977)
    ├── Perceptual (automatic, fast)
    └── Reasoning (controlled, effortful)
```

---

## Supporting Quotes for Taxonomy

### DOMAIN (Gaver, 1993)
From Chapter 7 index - covers "Ecological acoustics (Gaver)" distinguishing musical listening (sound properties) vs everyday listening (sound sources/events).

### PROCESSING DEPTH
**Quote from Chapter 4 (p. 117):**
> "most contemporary models of speech processing assume that speech is processed in a **series of stages**. The initial stage begins with translation of **acoustic signals** into a pattern of abstract representations, followed by **phonemic identification** and then **word or lexical processing** utilizing higher-level representations constructed from **contextual cues** and knowledge of prior subject matter."

**Quote from Chapter 4 (Processing Codes section):**
> "the sound stimulus will be initially coded in **acoustic format** and then will progress to a **lexical** and then **semantic code** as processing continues."

### PROCESSING DIRECTION
**Quote from Chapter 4:**
> "**Bottom-up processing** essentially refers to the influence of the direct stimulus input or sensory components of the stimulus. Bottom-up processing is therefore often referred to as **data-driven** or **data-limited** processing. Conversely, **top-down processing** refers to the influence of existing memories and knowledge structures (such as the use of context) and is therefore often referred to as **conceptually driven** or **resource-limited** processing."

### COGNITIVE DEMAND
**Quote from Chapter 5:**
> "The task may be so well learned to you that you do not need to put much mental effort or thought into it. It has become nearly '**automatic**,' to use Schneider and Shiffrin's (1977) term. However, to the novice... considerable concentration and mental effort may be required to perform the task."

---

## Verified Citations

| Citation | Status | Full Reference |
|----------|--------|----------------|
| **Gaver (1993)** | ✅ Verified | Gaver, W. W. (1993). What in the world do we hear?: An ecological approach to auditory event perception. *Ecological Psychology, 5*(1), 1-29. |
| **Norman & Bobrow (1975)** | ✅ Verified | Norman, D. A., & Bobrow, D. G. (1975). On data-limited and resource-limited processes. *Cognitive Psychology, 7*(1), 44-64. |
| **Schneider & Shiffrin (1977)** | ✅ Verified | Schneider, W., & Shiffrin, R. M. (1977). Controlled and automatic human information processing: I. Detection, search, and attention. *Psychological Review, 84*(1), 1-66. |
| **Baldwin (2012)** | ✅ Primary source | Baldwin, C. L. (2012). *Auditory cognition and human performance: Research and applications*. CRC Press. |

---

## Application to Benchmark Tasks

### Best-Fit Taxonomies for Audio Benchmarks

| Taxonomy | Applicability | Why |
|----------|---------------|-----|
| **Processing Depth** | ⭐⭐⭐⭐⭐ | Perfect fit - tasks vary by depth |
| **Processing Direction** | ⭐⭐⭐⭐⭐ | Maps to Perceptual/Reasoning split |
| **Domain (Gaver)** | ⭐⭐⭐⭐ | Maps to Speech/Sound/Music domains |
| **Cognitive Demand** | ⭐⭐⭐⭐ | Predicts task difficulty |
| **Baddeley WM** | ⭐⭐ | Only for long-form/memory tasks |
| **Wickens MRT** | ⭐ | Not applicable - single-modality |

### Processing Depth Examples

| Stage | Example Question |
|-------|------------------|
| Acoustic | "Is this note high or low?" |
| Phonological | "What language is being spoken?" |
| Lexical | "What word was said?" |
| Semantic | "What is the speaker's intent?" |

---

## Email Draft Sent to Supervisor

**Key points communicated:**
1. Obtained Baldwin (2012) through friend at Monash
2. Proposed Processing Depth + Processing Direction taxonomy
3. Noted MMAU-Pro already has Perceptual/Reasoning split (= Processing Direction)
4. Asked clarifying question about taxonomy purpose (gap identification vs human function mapping)
5. Noted neuropsychological tests (ERP, brain stem) don't translate to AI evaluation
6. Proposed next steps: map MMAU-Pro skills to taxonomy, find uncovered datasets

---

## Out of Scope (Confirmed)

Based on Baldwin's book and project focus:

| Out of Scope | Why |
|--------------|-----|
| ERP/Brain imaging tasks | Measures neural activity, not behavior |
| Audiometric tests (pure tone thresholds) | Clinical hearing assessment |
| Binaural localization | Requires spatial audio hardware |
| Music notation/theory | Visual/symbolic, not audio cognition |
| Speech production | Output, not input processing |

---

## Next Steps

1. **Map MMAU-Pro's 38 skills** to Processing Depth × Processing Direction taxonomy
2. **Identify gaps** where coverage is weak
3. **Find datasets** for under-covered areas
4. **Await supervisor feedback** on taxonomy purpose clarification

---

## Files Referenced

- `/papers/extracted-chapters/Chapter_12.md` (Chapter 4)
- `/papers/extracted-chapters/Chapter_13.md` (Chapter 5)
- `/papers/extracted-chapters/Chapter_14.md` (Chapter 6)
- `/output/benchmark-tasks.md`

---

*Session conducted with Claude Opus 4.5*

